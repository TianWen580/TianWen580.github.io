[
  {
    "id": 54224006,
    "slug": "zka8l2",
    "title": "TensorboardX训练可视化",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"db830417\"></a>\n## title: TensorboardX训练可视化date: 2021-08-07 22:43:00<br />tags: [深度学习, 语义分割, 可视化, TensorboardX]<br />categories: 计算机视觉特辑\n\n1.conda环境配置：<br />\n• tensorboardX2.2<br />\n• Tensorboard2.5.0<br />\n• PyTorch1.8.1<br />\n• Torchvision0.9.1<br />2.查看记录<br />\n• 首先学习以下tensorboardX怎么用。一般训练代码运行之后会同时生成tensorboardX的日志文件。这时复制日志文件所在文件夹路径，打开Anaconda命令行，切换环境至torch，输入图中语句为日志文件夹创建tensorboardX默认的本地端口（格式：tensorboard --logdir PATH）<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n• 执行得到端口地址，复制到浏览器打开即可查看训练可视化内容<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n• 关闭端口占用，只需长按CTRL + C<br />\n3.训练记录<br />\n• 导入SummaryWriter<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n• 在代码中初始化SummaryWriter实例，参数填记录的存储文件夹位置（有其他初始化方法，这里不常用）<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\n• 训练常用记录类型：<br />\n○ （scalar）单个数值<br />\n§ 参数：<br />\n□ Tag：该数据名称（如train_acc），不同名称数据会用独立图表表示<br />\n□ Scalar_value：数据值来源，一般是个python变量（如train_acc）<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalar()<br />\n○ （scalars）多个数值<br />\n多个数值的记录类型利用python字典生成日志<br />\n§ 参数：<br />\n□ Main_tag：该图表总的名称<br />\n□ Tag_scalar_dict：各类值的字典（如下）<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalars()<br />\n○ （graph）网络结构/运行图<br />\n§ 参数：<br />\n□ model：待可视化的网络模型<br />\n□ Input_to_model：输入的一组真图片或者伪造的零值图片<br />\n§ 用法：<br />\n□ 首先使用torch.randn(num,z,x,y)生成假数据，然后正常调用模型并切换至train状态<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE7.png#alt=%E5%9B%BE7)<br />\n□ 然后使用with语句生成SummaryWriter实例并添加运行图<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE8.png#alt=%E5%9B%BE8)<br />\n□ 当下文件夹目录会生成runs文件夹，这个文件路径为日志地址<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE9.gif#alt=%E5%9B%BE9)<br />\n• 其他记录类型：<br />\n• 一些问题<br />\n○ 如果执行 add 操作后没有实时在网页可视化界面看到效果，试试重启 tensorboard\n",
    "body_draft": "---\n\n\n<a name=\"db830417\"></a>\n## title: TensorboardX训练可视化date: 2021-08-07 22:43:00<br />tags: [深度学习, 语义分割, 可视化, TensorboardX]<br />categories: 计算机视觉特辑\n\n1.conda环境配置：<br />\n• tensorboardX2.2<br />\n• Tensorboard2.5.0<br />\n• PyTorch1.8.1<br />\n• Torchvision0.9.1<br />2.查看记录<br />\n• 首先学习以下tensorboardX怎么用。一般训练代码运行之后会同时生成tensorboardX的日志文件。这时复制日志文件所在文件夹路径，打开Anaconda命令行，切换环境至torch，输入图中语句为日志文件夹创建tensorboardX默认的本地端口（格式：tensorboard --logdir PATH）<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n• 执行得到端口地址，复制到浏览器打开即可查看训练可视化内容<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n• 关闭端口占用，只需长按CTRL + C<br />\n3.训练记录<br />\n• 导入SummaryWriter<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n• 在代码中初始化SummaryWriter实例，参数填记录的存储文件夹位置（有其他初始化方法，这里不常用）<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\n• 训练常用记录类型：<br />\n○ （scalar）单个数值<br />\n§ 参数：<br />\n□ Tag：该数据名称（如train_acc），不同名称数据会用独立图表表示<br />\n□ Scalar_value：数据值来源，一般是个python变量（如train_acc）<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalar()<br />\n○ （scalars）多个数值<br />\n多个数值的记录类型利用python字典生成日志<br />\n§ 参数：<br />\n□ Main_tag：该图表总的名称<br />\n□ Tag_scalar_dict：各类值的字典（如下）<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalars()<br />\n○ （graph）网络结构/运行图<br />\n§ 参数：<br />\n□ model：待可视化的网络模型<br />\n□ Input_to_model：输入的一组真图片或者伪造的零值图片<br />\n§ 用法：<br />\n□ 首先使用torch.randn(num,z,x,y)生成假数据，然后正常调用模型并切换至train状态<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE7.png#alt=%E5%9B%BE7)<br />\n□ 然后使用with语句生成SummaryWriter实例并添加运行图<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE8.png#alt=%E5%9B%BE8)<br />\n□ 当下文件夹目录会生成runs文件夹，这个文件路径为日志地址<br />\n![](TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE9.gif#alt=%E5%9B%BE9)<br />\n• 其他记录类型：<br />\n• 一些问题<br />\n○ 如果执行 add 操作后没有实时在网页可视化界面看到效果，试试重启 tensorboard\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--TensorboardX训练可视化-br---\ndate--2021-08-07-22-43-00-br---\ntags--[深度学习--语义分割--可视化--TensorboardX]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"db830417\">title: TensorboardX训练可视化<br />\ndate: 2021-08-07 22:43:00<br />\ntags: [深度学习, 语义分割, 可视化, TensorboardX]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.conda环境配置：<br />\n• tensorboardX<mark>2.2<br />\n• Tensorboard</mark>2.5.0<br />\n• PyTorch<mark>1.8.1<br />\n• Torchvision</mark>0.9.1</p><p>2.查看记录<br />\n• 首先学习以下tensorboardX怎么用。一般训练代码运行之后会同时生成tensorboardX的日志文件。这时复制日志文件所在文件夹路径，打开Anaconda命令行，切换环境至torch，输入图中语句为日志文件夹创建tensorboardX默认的本地端口（格式：tensorboard --logdir PATH）<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n• 执行得到端口地址，复制到浏览器打开即可查看训练可视化内容<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE2.png#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE3.png#alt=%E5%9B%BE3\" style=\"max-width: 600px;\" /><br />\n• 关闭端口占用，只需长按CTRL + C<br />\n3.训练记录<br />\n• 导入SummaryWriter<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE4.png#alt=%E5%9B%BE4\" style=\"max-width: 600px;\" /><br />\n• 在代码中初始化SummaryWriter实例，参数填记录的存储文件夹位置（有其他初始化方法，这里不常用）<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE5.png#alt=%E5%9B%BE5\" style=\"max-width: 600px;\" /><br />\n• 训练常用记录类型：<br />\n○ （scalar）单个数值<br />\n§ 参数：<br />\n□ Tag：该数据名称（如train_acc），不同名称数据会用独立图表表示<br />\n□ Scalar_value：数据值来源，一般是个python变量（如train_acc）<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalar()<br />\n○ （scalars）多个数值<br />\n多个数值的记录类型利用python字典生成日志<br />\n§ 参数：<br />\n□ Main_tag：该图表总的名称<br />\n□ Tag_scalar_dict：各类值的字典（如下）<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE6.png#alt=%E5%9B%BE6\" style=\"max-width: 600px;\" /><br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalars()<br />\n○ （graph）网络结构/运行图<br />\n§ 参数：<br />\n□ model：待可视化的网络模型<br />\n□ Input_to_model：输入的一组真图片或者伪造的零值图片<br />\n§ 用法：<br />\n□ 首先使用torch.randn(num,z,x,y)生成假数据，然后正常调用模型并切换至train状态<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE7.png#alt=%E5%9B%BE7\" style=\"max-width: 600px;\" /><br />\n□ 然后使用with语句生成SummaryWriter实例并添加运行图<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE8.png#alt=%E5%9B%BE8\" style=\"max-width: 600px;\" /><br />\n□ 当下文件夹目录会生成runs文件夹，这个文件路径为日志地址<br />\n<img src=\"TensorboardX%E8%AE%AD%E7%BB%83%E5%8F%AF%E8%A7%86%E5%8C%96/%E5%9B%BE9.gif#alt=%E5%9B%BE9\" style=\"max-width: 600px;\" /><br />\n• 其他记录类型：<br />\n• 一些问题<br />\n○ 如果执行 add 操作后没有实时在网页可视化界面看到效果，试试重启 tensorboard</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--TensorboardX训练可视化-br---\ndate--2021-08-07-22-43-00-br---\ntags--[深度学习--语义分割--可视化--TensorboardX]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"db830417\">title: TensorboardX训练可视化<br />\ndate: 2021-08-07 22:43:00<br />\ntags: [深度学习, 语义分割, 可视化, TensorboardX]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.conda环境配置：<br />\n• tensorboardX<mark>2.2<br />\n• Tensorboard</mark>2.5.0<br />\n• PyTorch<mark>1.8.1<br />\n• Torchvision</mark>0.9.1</p><p>2.查看记录<br />\n• 首先学习以下tensorboardX怎么用。一般训练代码运行之后会同时生成tensorboardX的日志文件。这时复制日志文件所在文件夹路径，打开Anaconda命令行，切换环境至torch，输入图中语句为日志文件夹创建tensorboardX默认的本地端口（格式：tensorboard --logdir PATH）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n• 执行得到端口地址，复制到浏览器打开即可查看训练可视化内容<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n• 关闭端口占用，只需长按CTRL + C<br />\n3.训练记录<br />\n• 导入SummaryWriter<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n• 在代码中初始化SummaryWriter实例，参数填记录的存储文件夹位置（有其他初始化方法，这里不常用）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\n• 训练常用记录类型：<br />\n○ （scalar）单个数值<br />\n§ 参数：<br />\n□ Tag：该数据名称（如train_acc），不同名称数据会用独立图表表示<br />\n□ Scalar_value：数据值来源，一般是个python变量（如train_acc）<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalar()<br />\n○ （scalars）多个数值<br />\n多个数值的记录类型利用python字典生成日志<br />\n§ 参数：<br />\n□ Main_tag：该图表总的名称<br />\n□ Tag_scalar_dict：各类值的字典（如下）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalars()<br />\n○ （graph）网络结构/运行图<br />\n§ 参数：<br />\n□ model：待可视化的网络模型<br />\n□ Input_to_model：输入的一组真图片或者伪造的零值图片<br />\n§ 用法：<br />\n□ 首先使用torch.randn(num,z,x,y)生成假数据，然后正常调用模型并切换至train状态<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card><br />\n□ 然后使用with语句生成SummaryWriter实例并添加运行图<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE8.png%22%2C%22alt%22%3A%22%E5%9B%BE8%22%7D\"></card><br />\n□ 当下文件夹目录会生成runs文件夹，这个文件路径为日志地址<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE9.gif%22%2C%22alt%22%3A%22%E5%9B%BE9%22%7D\"></card><br />\n• 其他记录类型：<br />\n• 一些问题<br />\n○ 如果执行 add 操作后没有实时在网页可视化界面看到效果，试试重启 tensorboard</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--TensorboardX训练可视化-br---\ndate--2021-08-07-22-43-00-br---\ntags--[深度学习--语义分割--可视化--TensorboardX]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"db830417\">title: TensorboardX训练可视化<br />\ndate: 2021-08-07 22:43:00<br />\ntags: [深度学习, 语义分割, 可视化, TensorboardX]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.conda环境配置：<br />\n• tensorboardX<mark>2.2<br />\n• Tensorboard</mark>2.5.0<br />\n• PyTorch<mark>1.8.1<br />\n• Torchvision</mark>0.9.1</p><p>2.查看记录<br />\n• 首先学习以下tensorboardX怎么用。一般训练代码运行之后会同时生成tensorboardX的日志文件。这时复制日志文件所在文件夹路径，打开Anaconda命令行，切换环境至torch，输入图中语句为日志文件夹创建tensorboardX默认的本地端口（格式：tensorboard --logdir PATH）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n• 执行得到端口地址，复制到浏览器打开即可查看训练可视化内容<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n• 关闭端口占用，只需长按CTRL + C<br />\n3.训练记录<br />\n• 导入SummaryWriter<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n• 在代码中初始化SummaryWriter实例，参数填记录的存储文件夹位置（有其他初始化方法，这里不常用）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\n• 训练常用记录类型：<br />\n○ （scalar）单个数值<br />\n§ 参数：<br />\n□ Tag：该数据名称（如train_acc），不同名称数据会用独立图表表示<br />\n□ Scalar_value：数据值来源，一般是个python变量（如train_acc）<br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalar()<br />\n○ （scalars）多个数值<br />\n多个数值的记录类型利用python字典生成日志<br />\n§ 参数：<br />\n□ Main_tag：该图表总的名称<br />\n□ Tag_scalar_dict：各类值的字典（如下）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n□ Global_step：存放当前epoch值<br />\n□ walltime：默认值time.time()，记录当下时间，一般填None不用<br />\n§ 用法：如writer.add_scalars()<br />\n○ （graph）网络结构/运行图<br />\n§ 参数：<br />\n□ model：待可视化的网络模型<br />\n□ Input_to_model：输入的一组真图片或者伪造的零值图片<br />\n§ 用法：<br />\n□ 首先使用torch.randn(num,z,x,y)生成假数据，然后正常调用模型并切换至train状态<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card><br />\n□ 然后使用with语句生成SummaryWriter实例并添加运行图<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE8.png%22%2C%22alt%22%3A%22%E5%9B%BE8%22%7D\"></card><br />\n□ 当下文件夹目录会生成runs文件夹，这个文件路径为日志地址<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22TensorboardX%25E8%25AE%25AD%25E7%25BB%2583%25E5%258F%25AF%25E8%25A7%2586%25E5%258C%2596%2F%25E5%259B%25BE9.gif%22%2C%22alt%22%3A%22%E5%9B%BE9%22%7D\"></card><br />\n• 其他记录类型：<br />\n• 一些问题<br />\n○ 如果执行 add 操作后没有实时在网页可视化界面看到效果，试试重启 tensorboard</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:05:00.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:05:00.000Z",
    "updated_at": "2021-09-27T07:04:08.000Z",
    "published_at": "2021-09-27T03:05:00.000Z",
    "first_published_at": "2021-09-27T03:05:00.000Z",
    "word_count": 610,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223997,
    "slug": "uqudv9",
    "title": "Pytorch·API部署WEB·ONNX",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"dbc0dfea\"></a>\n## title: Pytorch·API部署WEB·ONNXdate: 2021-08-07 23:25:16<br />tags: [深度学习, 语义分割, Pytorch, ONNX, Web开发]<br />categories: 计算机视觉特辑\n\n1.API接口，主要是通过中间商，为目标端暴露功能函数作为输入、处理、输出的桥梁。<br />2.WEB预测API开发（基于ONNX）<br />\n• ONNX是用于机器学习模型云端发布的文件格式，是适用于不同框架的规范工具，<br />\n参考视频：How to run PyTorch models in the browser with ONNX.js - YouTube<br />\n[https://www.youtube.com/watch?v=Vs730jsRgO8](https://www.youtube.com/watch?v=Vs730jsRgO8)<br />\n项目地址：pytorch-to-javascript-with-onnx - CodeSandbox<br />\n[https://codesandbox.io/s/vgzep?file=/index.html](https://codesandbox.io/s/vgzep?file=/index.html)\n\n• 训练并保存model.state_dict()<br />\n○ ONNX支持pt格式的模型介绍文件（model.state_dict()），训练时输入以下语句保存，也可以是pth格式<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n○ 注意搭建模型的时候检查激活函数是否支持ONNX，查询相关文档：<br />\n[https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md](https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md)<br />\n切换激活函数后还要更换对应的损失函数算法，比如softmax对应nn.functional.cross_entropy()<br />\n○ 另外，ONNX仅支持单GPU训练的model，切勿使用DataParellel等model。<br />\n○ 可以根据网络模型的github官网复制代码，搭建网络的时候要告知前端输入的图片尺寸，比如画布要绘制高清图可以预设网络输入尺寸为(280,280,4)，后期在池化层池化十倍即可。若onnx不能起作用，检查网络的pytorch语句是否有bug（如池化时不能对图片切片而必须使用torch.narrow(x)），可以查看pytorch官网文档或者中文文档的解释：<br />\n[https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html) or [https://pytorch-cn.readthedocs.io/zh/latest/](https://pytorch-cn.readthedocs.io/zh/latest/)\n\n• pt转onnx文件<br />\n○ 载入pt文件，切换为eval模式<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n○ 预先构造空的待测影像矩阵，并同相关参数传入torch.onnx.export()，导出onnx文件<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE3.png#alt=%E5%9B%BE3)\n\n• 前端对ONNX文件的获取和操作/API接口搭建<br />\n○ 首先，必须输入图中语句调用ONNX服务<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n○ 训练后生成的ONNX文件直接部署到前端项目文件夹，ONNX提供如下js操作以执行预测：<br />\n§ 新建Session，并在Session中载入model<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\n§ 获取服务器待预测图片，传入Tensor<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n§ 对图片执行预测<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE7.png#alt=%E5%9B%BE7)<br />\n§ 获取model输出Tensor<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE8.png#alt=%E5%9B%BE8)<br />\n§ 从输出Tensor提取出概率分布矩阵<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE9.png#alt=%E5%9B%BE9)<br />\n§ 提取概率最大对应的分类结果（转化为分类结果）<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE10.png#alt=%E5%9B%BE10)<br />\n○ 每次后端准备搭建API，以上都需要后端人员介绍给前端人员。\n\n3.上面内容只是以分类任务为例子，👉<br />\n[https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md](https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md) 有更多API搭建手段提供给分类、检测、分割等不同计算机视觉任务，关于遥感智能解译还要进一步探索。\n",
    "body_draft": "---\n\n\n<a name=\"dbc0dfea\"></a>\n## title: Pytorch·API部署WEB·ONNXdate: 2021-08-07 23:25:16<br />tags: [深度学习, 语义分割, Pytorch, ONNX, Web开发]<br />categories: 计算机视觉特辑\n\n1.API接口，主要是通过中间商，为目标端暴露功能函数作为输入、处理、输出的桥梁。<br />2.WEB预测API开发（基于ONNX）<br />\n• ONNX是用于机器学习模型云端发布的文件格式，是适用于不同框架的规范工具，<br />\n参考视频：How to run PyTorch models in the browser with ONNX.js - YouTube<br />\n[https://www.youtube.com/watch?v=Vs730jsRgO8](https://www.youtube.com/watch?v=Vs730jsRgO8)<br />\n项目地址：pytorch-to-javascript-with-onnx - CodeSandbox<br />\n[https://codesandbox.io/s/vgzep?file=/index.html](https://codesandbox.io/s/vgzep?file=/index.html)\n\n• 训练并保存model.state_dict()<br />\n○ ONNX支持pt格式的模型介绍文件（model.state_dict()），训练时输入以下语句保存，也可以是pth格式<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n○ 注意搭建模型的时候检查激活函数是否支持ONNX，查询相关文档：<br />\n[https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md](https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md)<br />\n切换激活函数后还要更换对应的损失函数算法，比如softmax对应nn.functional.cross_entropy()<br />\n○ 另外，ONNX仅支持单GPU训练的model，切勿使用DataParellel等model。<br />\n○ 可以根据网络模型的github官网复制代码，搭建网络的时候要告知前端输入的图片尺寸，比如画布要绘制高清图可以预设网络输入尺寸为(280,280,4)，后期在池化层池化十倍即可。若onnx不能起作用，检查网络的pytorch语句是否有bug（如池化时不能对图片切片而必须使用torch.narrow(x)），可以查看pytorch官网文档或者中文文档的解释：<br />\n[https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html) or [https://pytorch-cn.readthedocs.io/zh/latest/](https://pytorch-cn.readthedocs.io/zh/latest/)\n\n• pt转onnx文件<br />\n○ 载入pt文件，切换为eval模式<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n○ 预先构造空的待测影像矩阵，并同相关参数传入torch.onnx.export()，导出onnx文件<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE3.png#alt=%E5%9B%BE3)\n\n• 前端对ONNX文件的获取和操作/API接口搭建<br />\n○ 首先，必须输入图中语句调用ONNX服务<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n○ 训练后生成的ONNX文件直接部署到前端项目文件夹，ONNX提供如下js操作以执行预测：<br />\n§ 新建Session，并在Session中载入model<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\n§ 获取服务器待预测图片，传入Tensor<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n§ 对图片执行预测<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE7.png#alt=%E5%9B%BE7)<br />\n§ 获取model输出Tensor<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE8.png#alt=%E5%9B%BE8)<br />\n§ 从输出Tensor提取出概率分布矩阵<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE9.png#alt=%E5%9B%BE9)<br />\n§ 提取概率最大对应的分类结果（转化为分类结果）<br />\n![](Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE10.png#alt=%E5%9B%BE10)<br />\n○ 每次后端准备搭建API，以上都需要后端人员介绍给前端人员。\n\n3.上面内容只是以分类任务为例子，👉<br />\n[https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md](https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md) 有更多API搭建手段提供给分类、检测、分割等不同计算机视觉任务，关于遥感智能解译还要进一步探索。\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--Pytorch·API部署WEB·ONNX-br---\ndate--2021-08-07-23-25-16-br---\ntags--[深度学习--语义分割--Pytorch--ONNX--Web开发]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"dbc0dfea\">title: Pytorch·API部署WEB·ONNX<br />\ndate: 2021-08-07 23:25:16<br />\ntags: [深度学习, 语义分割, Pytorch, ONNX, Web开发]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.API接口，主要是通过中间商，为目标端暴露功能函数作为输入、处理、输出的桥梁。</p><p>2.WEB预测API开发（基于ONNX）<br />\n• ONNX是用于机器学习模型云端发布的文件格式，是适用于不同框架的规范工具，<br />\n参考视频：How to run PyTorch models in the browser with ONNX.js - YouTube<br />\n<a href=\"https://www.youtube.com/watch?v=Vs730jsRgO8\" target=\"_blank\">https://www.youtube.com/watch?v=Vs730jsRgO8</a><br />\n项目地址：pytorch-to-javascript-with-onnx - CodeSandbox<br />\n<a href=\"https://codesandbox.io/s/vgzep?file=/index.html\" target=\"_blank\">https://codesandbox.io/s/vgzep?file=/index.html</a></p><p><br /></p><p>• 训练并保存model.state_dict()<br />\n○ ONNX支持pt格式的模型介绍文件（model.state_dict()），训练时输入以下语句保存，也可以是pth格式<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n○ 注意搭建模型的时候检查激活函数是否支持ONNX，查询相关文档：<br />\n<a href=\"https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md\" target=\"_blank\">https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md</a><br />\n切换激活函数后还要更换对应的损失函数算法，比如softmax对应nn.functional.cross_entropy()<br />\n○ 另外，ONNX仅支持单GPU训练的model，切勿使用DataParellel等model。<br />\n○ 可以根据网络模型的github官网复制代码，搭建网络的时候要告知前端输入的图片尺寸，比如画布要绘制高清图可以预设网络输入尺寸为(280,280,4)，后期在池化层池化十倍即可。若onnx不能起作用，检查网络的pytorch语句是否有bug（如池化时不能对图片切片而必须使用torch.narrow(x)），可以查看pytorch官网文档或者中文文档的解释：<br />\n<a href=\"https://pytorch.org/docs/stable/index.html\" target=\"_blank\">https://pytorch.org/docs/stable/index.html</a> or <a href=\"https://pytorch-cn.readthedocs.io/zh/latest/\" target=\"_blank\">https://pytorch-cn.readthedocs.io/zh/latest/</a></p><p><br /></p><p>• pt转onnx文件<br />\n○ 载入pt文件，切换为eval模式<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE2.png#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n○ 预先构造空的待测影像矩阵，并同相关参数传入torch.onnx.export()，导出onnx文件<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE3.png#alt=%E5%9B%BE3\" style=\"max-width: 600px;\" /></p><p><br /></p><p>• 前端对ONNX文件的获取和操作/API接口搭建<br />\n○ 首先，必须输入图中语句调用ONNX服务<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE4.png#alt=%E5%9B%BE4\" style=\"max-width: 600px;\" /><br />\n○ 训练后生成的ONNX文件直接部署到前端项目文件夹，ONNX提供如下js操作以执行预测：<br />\n§ 新建Session，并在Session中载入model<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE5.png#alt=%E5%9B%BE5\" style=\"max-width: 600px;\" /><br />\n§ 获取服务器待预测图片，传入Tensor<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE6.png#alt=%E5%9B%BE6\" style=\"max-width: 600px;\" /><br />\n§ 对图片执行预测<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE7.png#alt=%E5%9B%BE7\" style=\"max-width: 600px;\" /><br />\n§ 获取model输出Tensor<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE8.png#alt=%E5%9B%BE8\" style=\"max-width: 600px;\" /><br />\n§ 从输出Tensor提取出概率分布矩阵<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE9.png#alt=%E5%9B%BE9\" style=\"max-width: 600px;\" /><br />\n§ 提取概率最大对应的分类结果（转化为分类结果）<br />\n<img src=\"Pytorch%C2%B7API%E9%83%A8%E7%BD%B2WEB%C2%B7ONNX/%E5%9B%BE10.png#alt=%E5%9B%BE10\" style=\"max-width: 600px;\" /><br />\n○ 每次后端准备搭建API，以上都需要后端人员介绍给前端人员。</p><p><br /></p><p>3.上面内容只是以分类任务为例子，👉<br />\n<a href=\"https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md\" target=\"_blank\">https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md</a> 有更多API搭建手段提供给分类、检测、分割等不同计算机视觉任务，关于遥感智能解译还要进一步探索。</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Pytorch·API部署WEB·ONNX-br---\ndate--2021-08-07-23-25-16-br---\ntags--[深度学习--语义分割--Pytorch--ONNX--Web开发]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"dbc0dfea\">title: Pytorch·API部署WEB·ONNX<br />\ndate: 2021-08-07 23:25:16<br />\ntags: [深度学习, 语义分割, Pytorch, ONNX, Web开发]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.API接口，主要是通过中间商，为目标端暴露功能函数作为输入、处理、输出的桥梁。</p><p>2.WEB预测API开发（基于ONNX）<br />\n• ONNX是用于机器学习模型云端发布的文件格式，是适用于不同框架的规范工具，<br />\n参考视频：How to run PyTorch models in the browser with ONNX.js - YouTube<br />\n<a href=\"https://www.youtube.com/watch?v=Vs730jsRgO8\" target=\"_blank\">https://www.youtube.com/watch?v=Vs730jsRgO8</a><br />\n项目地址：pytorch-to-javascript-with-onnx - CodeSandbox<br />\n<a href=\"https://codesandbox.io/s/vgzep?file=/index.html\" target=\"_blank\">https://codesandbox.io/s/vgzep?file=/index.html</a></p><p><br /></p><p>• 训练并保存model.state_dict()<br />\n○ ONNX支持pt格式的模型介绍文件（model.state_dict()），训练时输入以下语句保存，也可以是pth格式<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n○ 注意搭建模型的时候检查激活函数是否支持ONNX，查询相关文档：<br />\n<a href=\"https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md\" target=\"_blank\">https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md</a><br />\n切换激活函数后还要更换对应的损失函数算法，比如softmax对应nn.functional.cross_entropy()<br />\n○ 另外，ONNX仅支持单GPU训练的model，切勿使用DataParellel等model。<br />\n○ 可以根据网络模型的github官网复制代码，搭建网络的时候要告知前端输入的图片尺寸，比如画布要绘制高清图可以预设网络输入尺寸为(280,280,4)，后期在池化层池化十倍即可。若onnx不能起作用，检查网络的pytorch语句是否有bug（如池化时不能对图片切片而必须使用torch.narrow(x)），可以查看pytorch官网文档或者中文文档的解释：<br />\n<a href=\"https://pytorch.org/docs/stable/index.html\" target=\"_blank\">https://pytorch.org/docs/stable/index.html</a> or <a href=\"https://pytorch-cn.readthedocs.io/zh/latest/\" target=\"_blank\">https://pytorch-cn.readthedocs.io/zh/latest/</a></p><p><br /></p><p>• pt转onnx文件<br />\n○ 载入pt文件，切换为eval模式<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n○ 预先构造空的待测影像矩阵，并同相关参数传入torch.onnx.export()，导出onnx文件<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card></p><p><br /></p><p>• 前端对ONNX文件的获取和操作/API接口搭建<br />\n○ 首先，必须输入图中语句调用ONNX服务<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n○ 训练后生成的ONNX文件直接部署到前端项目文件夹，ONNX提供如下js操作以执行预测：<br />\n§ 新建Session，并在Session中载入model<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\n§ 获取服务器待预测图片，传入Tensor<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n§ 对图片执行预测<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card><br />\n§ 获取model输出Tensor<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE8.png%22%2C%22alt%22%3A%22%E5%9B%BE8%22%7D\"></card><br />\n§ 从输出Tensor提取出概率分布矩阵<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE9.png%22%2C%22alt%22%3A%22%E5%9B%BE9%22%7D\"></card><br />\n§ 提取概率最大对应的分类结果（转化为分类结果）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE10.png%22%2C%22alt%22%3A%22%E5%9B%BE10%22%7D\"></card><br />\n○ 每次后端准备搭建API，以上都需要后端人员介绍给前端人员。</p><p><br /></p><p>3.上面内容只是以分类任务为例子，👉<br />\n<a href=\"https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md\" target=\"_blank\">https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md</a> 有更多API搭建手段提供给分类、检测、分割等不同计算机视觉任务，关于遥感智能解译还要进一步探索。</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Pytorch·API部署WEB·ONNX-br---\ndate--2021-08-07-23-25-16-br---\ntags--[深度学习--语义分割--Pytorch--ONNX--Web开发]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"dbc0dfea\">title: Pytorch·API部署WEB·ONNX<br />\ndate: 2021-08-07 23:25:16<br />\ntags: [深度学习, 语义分割, Pytorch, ONNX, Web开发]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.API接口，主要是通过中间商，为目标端暴露功能函数作为输入、处理、输出的桥梁。</p><p>2.WEB预测API开发（基于ONNX）<br />\n• ONNX是用于机器学习模型云端发布的文件格式，是适用于不同框架的规范工具，<br />\n参考视频：How to run PyTorch models in the browser with ONNX.js - YouTube<br />\n<a href=\"https://www.youtube.com/watch?v=Vs730jsRgO8\" target=\"_blank\">https://www.youtube.com/watch?v=Vs730jsRgO8</a><br />\n项目地址：pytorch-to-javascript-with-onnx - CodeSandbox<br />\n<a href=\"https://codesandbox.io/s/vgzep?file=/index.html\" target=\"_blank\">https://codesandbox.io/s/vgzep?file=/index.html</a></p><p><br /></p><p>• 训练并保存model.state_dict()<br />\n○ ONNX支持pt格式的模型介绍文件（model.state_dict()），训练时输入以下语句保存，也可以是pth格式<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n○ 注意搭建模型的时候检查激活函数是否支持ONNX，查询相关文档：<br />\n<a href=\"https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md\" target=\"_blank\">https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/operators.md</a><br />\n切换激活函数后还要更换对应的损失函数算法，比如softmax对应nn.functional.cross_entropy()<br />\n○ 另外，ONNX仅支持单GPU训练的model，切勿使用DataParellel等model。<br />\n○ 可以根据网络模型的github官网复制代码，搭建网络的时候要告知前端输入的图片尺寸，比如画布要绘制高清图可以预设网络输入尺寸为(280,280,4)，后期在池化层池化十倍即可。若onnx不能起作用，检查网络的pytorch语句是否有bug（如池化时不能对图片切片而必须使用torch.narrow(x)），可以查看pytorch官网文档或者中文文档的解释：<br />\n<a href=\"https://pytorch.org/docs/stable/index.html\" target=\"_blank\">https://pytorch.org/docs/stable/index.html</a> or <a href=\"https://pytorch-cn.readthedocs.io/zh/latest/\" target=\"_blank\">https://pytorch-cn.readthedocs.io/zh/latest/</a></p><p><br /></p><p>• pt转onnx文件<br />\n○ 载入pt文件，切换为eval模式<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n○ 预先构造空的待测影像矩阵，并同相关参数传入torch.onnx.export()，导出onnx文件<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card></p><p><br /></p><p>• 前端对ONNX文件的获取和操作/API接口搭建<br />\n○ 首先，必须输入图中语句调用ONNX服务<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n○ 训练后生成的ONNX文件直接部署到前端项目文件夹，ONNX提供如下js操作以执行预测：<br />\n§ 新建Session，并在Session中载入model<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\n§ 获取服务器待预测图片，传入Tensor<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n§ 对图片执行预测<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card><br />\n§ 获取model输出Tensor<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE8.png%22%2C%22alt%22%3A%22%E5%9B%BE8%22%7D\"></card><br />\n§ 从输出Tensor提取出概率分布矩阵<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE9.png%22%2C%22alt%22%3A%22%E5%9B%BE9%22%7D\"></card><br />\n§ 提取概率最大对应的分类结果（转化为分类结果）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7API%25E9%2583%25A8%25E7%25BD%25B2WEB%25C2%25B7ONNX%2F%25E5%259B%25BE10.png%22%2C%22alt%22%3A%22%E5%9B%BE10%22%7D\"></card><br />\n○ 每次后端准备搭建API，以上都需要后端人员介绍给前端人员。</p><p><br /></p><p>3.上面内容只是以分类任务为例子，👉<br />\n<a href=\"https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md\" target=\"_blank\">https://github.com/microsoft/onnxjs/blob/v0.1.8/docs/api.md</a> 有更多API搭建手段提供给分类、检测、分割等不同计算机视觉任务，关于遥感智能解译还要进一步探索。</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:55.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:55.000Z",
    "updated_at": "2021-09-27T07:04:08.000Z",
    "published_at": "2021-09-27T03:04:55.000Z",
    "first_published_at": "2021-09-27T03:04:55.000Z",
    "word_count": 699,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223980,
    "slug": "mao648",
    "title": "Pytorch·GPU训练-单-多",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"da1de03e\"></a>\n## title: Pytorch·GPU训练(单/多)date: 2021-08-07 23:20:37<br />tags: [深度学习, 语义分割, Pytorch]<br />categories: 计算机视觉特辑\n\n在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）<br />CUDA安装参考该笔记：Keras·GPU训练（单/多）<br />\n1.依赖库版本：<br />\n• Torch<br />\n• Torchvision<br />\n2.安装PyTorch：<br />\n• 进入PyTorch官网 Start Locally | PyTorch 选择版本，在conda运行所给安装语句<br />\n![](Pytorch%C2%B7GPU%E8%AE%AD%E7%BB%83-%E5%8D%95-%E5%A4%9A/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n• 然后参照Keras的gpu环境配置，安装CUDA11.1和对应的cudnn。<br />\n3.单gpu训练<br />\n• 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(\"cuda:0\"iftorch.cuda.is_available()else\"cpu\")<br />\n4.多gpu训练<br />\n• Torch.nn.DataParallel<br />\n○ 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(\"cuda:0\"iftorch.cuda.is_available()else\"cpu\")<br />\n○ 输入如下语句生成多gpu的model<br />\nPar_model = nn.DataParallel(MyNet())<br />\nPar_model = Par_model.cuda(device)   #model加载到gpu\n",
    "body_draft": "---\n\n\n<a name=\"da1de03e\"></a>\n## title: Pytorch·GPU训练(单/多)date: 2021-08-07 23:20:37<br />tags: [深度学习, 语义分割, Pytorch]<br />categories: 计算机视觉特辑\n\n在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）<br />CUDA安装参考该笔记：Keras·GPU训练（单/多）<br />\n1.依赖库版本：<br />\n• Torch<br />\n• Torchvision<br />\n2.安装PyTorch：<br />\n• 进入PyTorch官网 Start Locally | PyTorch 选择版本，在conda运行所给安装语句<br />\n![](Pytorch%C2%B7GPU%E8%AE%AD%E7%BB%83-%E5%8D%95-%E5%A4%9A/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n• 然后参照Keras的gpu环境配置，安装CUDA11.1和对应的cudnn。<br />\n3.单gpu训练<br />\n• 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(\"cuda:0\"iftorch.cuda.is_available()else\"cpu\")<br />\n4.多gpu训练<br />\n• Torch.nn.DataParallel<br />\n○ 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(\"cuda:0\"iftorch.cuda.is_available()else\"cpu\")<br />\n○ 输入如下语句生成多gpu的model<br />\nPar_model = nn.DataParallel(MyNet())<br />\nPar_model = Par_model.cuda(device)   #model加载到gpu\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--Pytorch·GPU训练(单-多)-br---\ndate--2021-08-07-23-20-37-br---\ntags--[深度学习--语义分割--Pytorch]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"da1de03e\">title: Pytorch·GPU训练(单/多)<br />\ndate: 2021-08-07 23:20:37<br />\ntags: [深度学习, 语义分割, Pytorch]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）</p><p>CUDA安装参考该笔记：Keras·GPU训练（单/多）<br />\n1.依赖库版本：<br />\n• Torch<br />\n• Torchvision<br />\n2.安装PyTorch：<br />\n• 进入PyTorch官网 Start Locally | PyTorch 选择版本，在conda运行所给安装语句<br />\n<img src=\"Pytorch%C2%B7GPU%E8%AE%AD%E7%BB%83-%E5%8D%95-%E5%A4%9A/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n• 然后参照Keras的gpu环境配置，安装CUDA11.1和对应的cudnn。<br />\n3.单gpu训练<br />\n• 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(&quot;cuda:0&quot;iftorch.cuda.is_available()else&quot;cpu&quot;)<br />\n4.多gpu训练<br />\n• Torch.nn.DataParallel<br />\n○ 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(&quot;cuda:0&quot;iftorch.cuda.is_available()else&quot;cpu&quot;)<br />\n○ 输入如下语句生成多gpu的model<br />\nPar_model = nn.DataParallel(MyNet())<br />\nPar_model = Par_model.cuda(device)   #model加载到gpu</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Pytorch·GPU训练(单-多)-br---\ndate--2021-08-07-23-20-37-br---\ntags--[深度学习--语义分割--Pytorch]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"da1de03e\">title: Pytorch·GPU训练(单/多)<br />\ndate: 2021-08-07 23:20:37<br />\ntags: [深度学习, 语义分割, Pytorch]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）</p><p>CUDA安装参考该笔记：Keras·GPU训练（单/多）<br />\n1.依赖库版本：<br />\n• Torch<br />\n• Torchvision<br />\n2.安装PyTorch：<br />\n• 进入PyTorch官网 Start Locally | PyTorch 选择版本，在conda运行所给安装语句<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583-%25E5%258D%2595-%25E5%25A4%259A%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n• 然后参照Keras的gpu环境配置，安装CUDA11.1和对应的cudnn。<br />\n3.单gpu训练<br />\n• 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(&quot;cuda:0&quot;iftorch.cuda.is_available()else&quot;cpu&quot;)<br />\n4.多gpu训练<br />\n• Torch.nn.DataParallel<br />\n○ 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(&quot;cuda:0&quot;iftorch.cuda.is_available()else&quot;cpu&quot;)<br />\n○ 输入如下语句生成多gpu的model<br />\nPar_model = nn.DataParallel(MyNet())<br />\nPar_model = Par_model.cuda(device)   #model加载到gpu</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Pytorch·GPU训练(单-多)-br---\ndate--2021-08-07-23-20-37-br---\ntags--[深度学习--语义分割--Pytorch]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"da1de03e\">title: Pytorch·GPU训练(单/多)<br />\ndate: 2021-08-07 23:20:37<br />\ntags: [深度学习, 语义分割, Pytorch]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）</p><p>CUDA安装参考该笔记：Keras·GPU训练（单/多）<br />\n1.依赖库版本：<br />\n• Torch<br />\n• Torchvision<br />\n2.安装PyTorch：<br />\n• 进入PyTorch官网 Start Locally | PyTorch 选择版本，在conda运行所给安装语句<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Pytorch%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583-%25E5%258D%2595-%25E5%25A4%259A%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n• 然后参照Keras的gpu环境配置，安装CUDA11.1和对应的cudnn。<br />\n3.单gpu训练<br />\n• 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(&quot;cuda:0&quot;iftorch.cuda.is_available()else&quot;cpu&quot;)<br />\n4.多gpu训练<br />\n• Torch.nn.DataParallel<br />\n○ 输入如下语句，指定搜索gpu的起始位置<br />\ndevice=torch.device(&quot;cuda:0&quot;iftorch.cuda.is_available()else&quot;cpu&quot;)<br />\n○ 输入如下语句生成多gpu的model<br />\nPar_model = nn.DataParallel(MyNet())<br />\nPar_model = Par_model.cuda(device)   #model加载到gpu</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:50.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:50.000Z",
    "updated_at": "2021-09-27T07:04:08.000Z",
    "published_at": "2021-09-27T03:04:50.000Z",
    "first_published_at": "2021-09-27T03:04:50.000Z",
    "word_count": 233,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223972,
    "slug": "xkk3s7",
    "title": "Keras·GPU训练（单-多）",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"8de338e2\"></a>\n## title: Keras·gpu训练（单\\多）date: 2021-08-07 23:40:18<br />tags: [深度学习, 语义分割, Keras]<br />categories: 计算机视觉特辑\n\n在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）<br />1.版本号：<br />\n• keras2.2.4<br />\n• Tensorflow-gpu1.12.0<br />\n• CUDA9.0.176<br />\n• cuDNN7.6.5 for CUDA 9.0<br />\n• Scikit-image<br />\n• Opencv-python<br />\n2.CUDA下载<br />\n• 从 [https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive) 中打开下载中心，找到相应版本，点击版本号即可进入下载页面<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n• 选择要下载的平台、版本号等，点击DOWNLOAD即可<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n3.cuDNN下载·安装<br />\n• 首先，把CUDA安装好，从 NVIDIA cuDNN | NVIDIA Developer [https://developer.nvidia.com/zh-cn/cudnn](https://developer.nvidia.com/zh-cn/cudnn)<br />\n中打开cuDNN中心，点击“下载cuDNN”，登录之后填写问卷即可下载。最后bin、include、lib三个文件夹里的文件复制到CUDA的对应文件夹中就行了。<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\n4.单gpu训练/多gpu训练<br />\n• 单gpu非常简单，只需要写图中语句即可用keras实现单gpu训练<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n• 多gpu需要用到muti函数生成模型，代码如下<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE7.png#alt=%E5%9B%BE7)<br />\n5.找不到第二条gpu<br />\n• 有时候keras识别不了电脑的第二条gpu，执行muti会报错如下：<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE8.png#alt=%E5%9B%BE8)<br />\n• 我这次是因为执行了这个语句造成的，这个语句只能供单gpu的model使用<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE9.png#alt=%E5%9B%BE9)\n",
    "body_draft": "---\n\n\n<a name=\"8de338e2\"></a>\n## title: Keras·gpu训练（单\\多）date: 2021-08-07 23:40:18<br />tags: [深度学习, 语义分割, Keras]<br />categories: 计算机视觉特辑\n\n在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）<br />1.版本号：<br />\n• keras2.2.4<br />\n• Tensorflow-gpu1.12.0<br />\n• CUDA9.0.176<br />\n• cuDNN7.6.5 for CUDA 9.0<br />\n• Scikit-image<br />\n• Opencv-python<br />\n2.CUDA下载<br />\n• 从 [https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive) 中打开下载中心，找到相应版本，点击版本号即可进入下载页面<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n• 选择要下载的平台、版本号等，点击DOWNLOAD即可<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n3.cuDNN下载·安装<br />\n• 首先，把CUDA安装好，从 NVIDIA cuDNN | NVIDIA Developer [https://developer.nvidia.com/zh-cn/cudnn](https://developer.nvidia.com/zh-cn/cudnn)<br />\n中打开cuDNN中心，点击“下载cuDNN”，登录之后填写问卷即可下载。最后bin、include、lib三个文件夹里的文件复制到CUDA的对应文件夹中就行了。<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\n4.单gpu训练/多gpu训练<br />\n• 单gpu非常简单，只需要写图中语句即可用keras实现单gpu训练<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n• 多gpu需要用到muti函数生成模型，代码如下<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE7.png#alt=%E5%9B%BE7)<br />\n5.找不到第二条gpu<br />\n• 有时候keras识别不了电脑的第二条gpu，执行muti会报错如下：<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE8.png#alt=%E5%9B%BE8)<br />\n• 我这次是因为执行了这个语句造成的，这个语句只能供单gpu的model使用<br />\n![](Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE9.png#alt=%E5%9B%BE9)\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--Keras·gpu训练（单\\多）-br---\ndate--2021-08-07-23-40-18-br---\ntags--[深度学习--语义分割--Keras]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"8de338e2\">title: Keras·gpu训练（单\\多）<br />\ndate: 2021-08-07 23:40:18<br />\ntags: [深度学习, 语义分割, Keras]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）</p><p>1.版本号：<br />\n• keras<mark>2.2.4<br />\n• Tensorflow-gpu</mark>1.12.0<br />\n• CUDA<mark>9.0.176<br />\n• cuDNN</mark>7.6.5 for CUDA 9.0<br />\n• Scikit-image<br />\n• Opencv-python<br />\n2.CUDA下载<br />\n• 从 <a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\">https://developer.nvidia.com/cuda-toolkit-archive</a> 中打开下载中心，找到相应版本，点击版本号即可进入下载页面<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n• 选择要下载的平台、版本号等，点击DOWNLOAD即可<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE2.png#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n3.cuDNN下载·安装<br />\n• 首先，把CUDA安装好，从 NVIDIA cuDNN | NVIDIA Developer <a href=\"https://developer.nvidia.com/zh-cn/cudnn\" target=\"_blank\">https://developer.nvidia.com/zh-cn/cudnn</a><br />\n中打开cuDNN中心，点击“下载cuDNN”，登录之后填写问卷即可下载。最后bin、include、lib三个文件夹里的文件复制到CUDA的对应文件夹中就行了。<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE3.png#alt=%E5%9B%BE3\" style=\"max-width: 600px;\" /><br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE4.png#alt=%E5%9B%BE4\" style=\"max-width: 600px;\" /><br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE5.png#alt=%E5%9B%BE5\" style=\"max-width: 600px;\" /><br />\n4.单gpu训练/多gpu训练<br />\n• 单gpu非常简单，只需要写图中语句即可用keras实现单gpu训练<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE6.png#alt=%E5%9B%BE6\" style=\"max-width: 600px;\" /><br />\n• 多gpu需要用到muti函数生成模型，代码如下<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE7.png#alt=%E5%9B%BE7\" style=\"max-width: 600px;\" /><br />\n5.找不到第二条gpu<br />\n• 有时候keras识别不了电脑的第二条gpu，执行muti会报错如下：<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE8.png#alt=%E5%9B%BE8\" style=\"max-width: 600px;\" /><br />\n• 我这次是因为执行了这个语句造成的，这个语句只能供单gpu的model使用<br />\n<img src=\"Keras%C2%B7GPU%E8%AE%AD%E7%BB%83%EF%BC%88%E5%8D%95-%E5%A4%9A%EF%BC%89/%E5%9B%BE9.png#alt=%E5%9B%BE9\" style=\"max-width: 600px;\" /></p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Keras·gpu训练（单\\多）-br---\ndate--2021-08-07-23-40-18-br---\ntags--[深度学习--语义分割--Keras]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"8de338e2\">title: Keras·gpu训练（单\\多）<br />\ndate: 2021-08-07 23:40:18<br />\ntags: [深度学习, 语义分割, Keras]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）</p><p>1.版本号：<br />\n• keras<mark>2.2.4<br />\n• Tensorflow-gpu</mark>1.12.0<br />\n• CUDA<mark>9.0.176<br />\n• cuDNN</mark>7.6.5 for CUDA 9.0<br />\n• Scikit-image<br />\n• Opencv-python<br />\n2.CUDA下载<br />\n• 从 <a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\">https://developer.nvidia.com/cuda-toolkit-archive</a> 中打开下载中心，找到相应版本，点击版本号即可进入下载页面<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n• 选择要下载的平台、版本号等，点击DOWNLOAD即可<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n3.cuDNN下载·安装<br />\n• 首先，把CUDA安装好，从 NVIDIA cuDNN | NVIDIA Developer <a href=\"https://developer.nvidia.com/zh-cn/cudnn\" target=\"_blank\">https://developer.nvidia.com/zh-cn/cudnn</a><br />\n中打开cuDNN中心，点击“下载cuDNN”，登录之后填写问卷即可下载。最后bin、include、lib三个文件夹里的文件复制到CUDA的对应文件夹中就行了。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\n4.单gpu训练/多gpu训练<br />\n• 单gpu非常简单，只需要写图中语句即可用keras实现单gpu训练<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n• 多gpu需要用到muti函数生成模型，代码如下<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card><br />\n5.找不到第二条gpu<br />\n• 有时候keras识别不了电脑的第二条gpu，执行muti会报错如下：<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE8.png%22%2C%22alt%22%3A%22%E5%9B%BE8%22%7D\"></card><br />\n• 我这次是因为执行了这个语句造成的，这个语句只能供单gpu的model使用<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE9.png%22%2C%22alt%22%3A%22%E5%9B%BE9%22%7D\"></card></p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Keras·gpu训练（单\\多）-br---\ndate--2021-08-07-23-40-18-br---\ntags--[深度学习--语义分割--Keras]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"8de338e2\">title: Keras·gpu训练（单\\多）<br />\ndate: 2021-08-07 23:40:18<br />\ntags: [深度学习, 语义分割, Keras]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>在一切开始前，请确定计算机拥有英伟达的显卡。<br />\n（不是英特尔！不是英特尔！不是英特尔！）</p><p>1.版本号：<br />\n• keras<mark>2.2.4<br />\n• Tensorflow-gpu</mark>1.12.0<br />\n• CUDA<mark>9.0.176<br />\n• cuDNN</mark>7.6.5 for CUDA 9.0<br />\n• Scikit-image<br />\n• Opencv-python<br />\n2.CUDA下载<br />\n• 从 <a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\">https://developer.nvidia.com/cuda-toolkit-archive</a> 中打开下载中心，找到相应版本，点击版本号即可进入下载页面<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n• 选择要下载的平台、版本号等，点击DOWNLOAD即可<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n3.cuDNN下载·安装<br />\n• 首先，把CUDA安装好，从 NVIDIA cuDNN | NVIDIA Developer <a href=\"https://developer.nvidia.com/zh-cn/cudnn\" target=\"_blank\">https://developer.nvidia.com/zh-cn/cudnn</a><br />\n中打开cuDNN中心，点击“下载cuDNN”，登录之后填写问卷即可下载。最后bin、include、lib三个文件夹里的文件复制到CUDA的对应文件夹中就行了。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\n4.单gpu训练/多gpu训练<br />\n• 单gpu非常简单，只需要写图中语句即可用keras实现单gpu训练<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n• 多gpu需要用到muti函数生成模型，代码如下<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card><br />\n5.找不到第二条gpu<br />\n• 有时候keras识别不了电脑的第二条gpu，执行muti会报错如下：<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE8.png%22%2C%22alt%22%3A%22%E5%9B%BE8%22%7D\"></card><br />\n• 我这次是因为执行了这个语句造成的，这个语句只能供单gpu的model使用<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Keras%25C2%25B7GPU%25E8%25AE%25AD%25E7%25BB%2583%25EF%25BC%2588%25E5%258D%2595-%25E5%25A4%259A%25EF%25BC%2589%2F%25E5%259B%25BE9.png%22%2C%22alt%22%3A%22%E5%9B%BE9%22%7D\"></card></p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:45.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:45.000Z",
    "updated_at": "2021-09-27T07:04:08.000Z",
    "published_at": "2021-09-27T03:04:45.000Z",
    "first_published_at": "2021-09-27T03:04:45.000Z",
    "word_count": 357,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223962,
    "slug": "ug2u1x",
    "title": "GIS的应用",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"9885d681\"></a>\n## title: GIS的应用date: 2021-07-12 21:50:03<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.输入（蓝）、处理（橙）、输出（绿）：<br />\n• 输入处理输出是最基本最简化的应用逻辑\n```\n![图1](GIS的应用/图1.png)\n```\n\n2.GIS模型+具体行业模型（集成）<br />\n• 举例复杂应用：水务行业的排水管网SWMM模型（排水管网属于GIS模型，SWMM属于税务行业模型）<br />\n○ 对应GISer的思想：<br />\n§ 给排水管建模<br />\n§ 分层：根据用户需求分析得到的设备类型抽象图层：检查井、管线、汇水区……<br />\n§ 抽象：<br />\n□ 检查井，点类型：坐标、高程……<br />\n□ 管线，线类型：上下游井、埋深、管长、管径……<br />\n□ 汇水区，面类型：面积……<br />\n○ 针对思想的复杂应用构建：<br />\n§ 输入：<br />\n□ 检查井：坐标、高程……<<DEM高程提取<br />\n□ 管线：上下游井、埋深、管长、管径……<<上下游网络拓扑<br />\n□ 汇水区：面积……<<小流域Basin划分工具<br />\n§ 处理：<br />\n□ SWMM模型引擎（和GIS关系不大，主要来源于行业模型）<br />\n§ 输出（行业用户对应需求）：<br />\n□ 检查井的水位变化序列的动态专题渲染<br />\n□ 管线流量、充满度变化序列的动态专题渲染\n",
    "body_draft": "---\n\n\n<a name=\"9885d681\"></a>\n## title: GIS的应用date: 2021-07-12 21:50:03<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.输入（蓝）、处理（橙）、输出（绿）：<br />\n• 输入处理输出是最基本最简化的应用逻辑\n```\n![图1](GIS的应用/图1.png)\n```\n\n2.GIS模型+具体行业模型（集成）<br />\n• 举例复杂应用：水务行业的排水管网SWMM模型（排水管网属于GIS模型，SWMM属于税务行业模型）<br />\n○ 对应GISer的思想：<br />\n§ 给排水管建模<br />\n§ 分层：根据用户需求分析得到的设备类型抽象图层：检查井、管线、汇水区……<br />\n§ 抽象：<br />\n□ 检查井，点类型：坐标、高程……<br />\n□ 管线，线类型：上下游井、埋深、管长、管径……<br />\n□ 汇水区，面类型：面积……<br />\n○ 针对思想的复杂应用构建：<br />\n§ 输入：<br />\n□ 检查井：坐标、高程……<<DEM高程提取<br />\n□ 管线：上下游井、埋深、管长、管径……<<上下游网络拓扑<br />\n□ 汇水区：面积……<<小流域Basin划分工具<br />\n§ 处理：<br />\n□ SWMM模型引擎（和GIS关系不大，主要来源于行业模型）<br />\n§ 输出（行业用户对应需求）：<br />\n□ 检查井的水位变化序列的动态专题渲染<br />\n□ 管线流量、充满度变化序列的动态专题渲染\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--GIS的应用-br---\ndate--2021-07-12-21-50-03-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"9885d681\">title: GIS的应用<br />\ndate: 2021-07-12 21:50:03<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.输入（蓝）、处理（橙）、输出（绿）：<br />\n• 输入处理输出是最基本最简化的应用逻辑</p><pre><code>![图1](GIS的应用/图1.png)</code></pre><p><br /></p><p>2.GIS模型+具体行业模型（集成）<br />\n• 举例复杂应用：水务行业的排水管网SWMM模型（排水管网属于GIS模型，SWMM属于税务行业模型）<br />\n○ 对应GISer的思想：<br />\n§ 给排水管建模<br />\n§ 分层：根据用户需求分析得到的设备类型抽象图层：检查井、管线、汇水区……<br />\n§ 抽象：<br />\n□ 检查井，点类型：坐标、高程……<br />\n□ 管线，线类型：上下游井、埋深、管长、管径……<br />\n□ 汇水区，面类型：面积……<br />\n○ 针对思想的复杂应用构建：<br />\n§ 输入：<br />\n□ 检查井：坐标、高程……&lt;&lt;DEM高程提取<br />\n□ 管线：上下游井、埋深、管长、管径……&lt;&lt;上下游网络拓扑<br />\n□ 汇水区：面积……&lt;&lt;小流域Basin划分工具<br />\n§ 处理：<br />\n□ SWMM模型引擎（和GIS关系不大，主要来源于行业模型）<br />\n§ 输出（行业用户对应需求）：<br />\n□ 检查井的水位变化序列的动态专题渲染<br />\n□ 管线流量、充满度变化序列的动态专题渲染</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GIS的应用-br---\ndate--2021-07-12-21-50-03-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"9885d681\">title: GIS的应用<br />\ndate: 2021-07-12 21:50:03<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.输入（蓝）、处理（橙）、输出（绿）：<br />\n• 输入处理输出是最基本最简化的应用逻辑</p><card type=\"block\" name=\"codeblock\" value=\"data:%7B%22id%22%3A%22da153f6a%22%2C%22code%22%3A%22!%5B%E5%9B%BE1%5D(GIS%E7%9A%84%E5%BA%94%E7%94%A8%2F%E5%9B%BE1.png)%22%7D\"></card><p><br /></p><p>2.GIS模型+具体行业模型（集成）<br />\n• 举例复杂应用：水务行业的排水管网SWMM模型（排水管网属于GIS模型，SWMM属于税务行业模型）<br />\n○ 对应GISer的思想：<br />\n§ 给排水管建模<br />\n§ 分层：根据用户需求分析得到的设备类型抽象图层：检查井、管线、汇水区……<br />\n§ 抽象：<br />\n□ 检查井，点类型：坐标、高程……<br />\n□ 管线，线类型：上下游井、埋深、管长、管径……<br />\n□ 汇水区，面类型：面积……<br />\n○ 针对思想的复杂应用构建：<br />\n§ 输入：<br />\n□ 检查井：坐标、高程……&lt;&lt;DEM高程提取<br />\n□ 管线：上下游井、埋深、管长、管径……&lt;&lt;上下游网络拓扑<br />\n□ 汇水区：面积……&lt;&lt;小流域Basin划分工具<br />\n§ 处理：<br />\n□ SWMM模型引擎（和GIS关系不大，主要来源于行业模型）<br />\n§ 输出（行业用户对应需求）：<br />\n□ 检查井的水位变化序列的动态专题渲染<br />\n□ 管线流量、充满度变化序列的动态专题渲染</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GIS的应用-br---\ndate--2021-07-12-21-50-03-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"9885d681\">title: GIS的应用<br />\ndate: 2021-07-12 21:50:03<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.输入（蓝）、处理（橙）、输出（绿）：<br />\n• 输入处理输出是最基本最简化的应用逻辑</p><card type=\"block\" name=\"codeblock\" value=\"data:%7B%22id%22%3A%22da153f6a%22%2C%22code%22%3A%22!%5B%E5%9B%BE1%5D(GIS%E7%9A%84%E5%BA%94%E7%94%A8%2F%E5%9B%BE1.png)%22%7D\"></card><p><br /></p><p>2.GIS模型+具体行业模型（集成）<br />\n• 举例复杂应用：水务行业的排水管网SWMM模型（排水管网属于GIS模型，SWMM属于税务行业模型）<br />\n○ 对应GISer的思想：<br />\n§ 给排水管建模<br />\n§ 分层：根据用户需求分析得到的设备类型抽象图层：检查井、管线、汇水区……<br />\n§ 抽象：<br />\n□ 检查井，点类型：坐标、高程……<br />\n□ 管线，线类型：上下游井、埋深、管长、管径……<br />\n□ 汇水区，面类型：面积……<br />\n○ 针对思想的复杂应用构建：<br />\n§ 输入：<br />\n□ 检查井：坐标、高程……&lt;&lt;DEM高程提取<br />\n□ 管线：上下游井、埋深、管长、管径……&lt;&lt;上下游网络拓扑<br />\n□ 汇水区：面积……&lt;&lt;小流域Basin划分工具<br />\n§ 处理：<br />\n□ SWMM模型引擎（和GIS关系不大，主要来源于行业模型）<br />\n§ 输出（行业用户对应需求）：<br />\n□ 检查井的水位变化序列的动态专题渲染<br />\n□ 管线流量、充满度变化序列的动态专题渲染</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:40.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:40.000Z",
    "updated_at": "2021-09-27T07:04:08.000Z",
    "published_at": "2021-09-27T03:04:40.000Z",
    "first_published_at": "2021-09-27T03:04:40.000Z",
    "word_count": 389,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223953,
    "slug": "xyq9rx",
    "title": "GISer的思想",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"fb311eb6\"></a>\n## title: GISer的思想date: 2021-07-12 21:49:50<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.ESRI出版的《Modeling Our World》讲解了成熟的GIS思想方法<br />\n2.GIS相比传统制图工具：<br />\n• 制图工具只能在不同维度制作可视的现实还原，无法展开空间分析。GIS相当于传统制图的下一发展阶段，为整个世界创造了空间分析的可视化制图方法。值得一提的是，以CAD为代表的传统制图和GIS齐头并进，各有千秋，应当进一步融合。<br />3.分层概念：<br />\n• Feature In FeatureClass：一座城市有许多独立的、多种类的水厂，整个城市的各种水厂形成单独的群体。这就像当于面向对象中抽象的概念，各种feature继承了featureClass基类，但是feature和featureClass在GIS中都是作为独立一层存储的。<br />\n4.抽象简化：<br />\n• 空间抽象：现实信息组织入虚拟一般有抽象简化的过程，空间万物都是立体的，但是可以抽象成点线面存储在GIS中。<br />\n• 属性抽象：就像猫狗都是生物但是不同种类一般，不同的空间要素不能在同一图层，因为字段组织不一致。但是他们抽象出来的特征可能一致，即可能属于同一图层。<br />\n![](GISer%E7%9A%84%E6%80%9D%E6%83%B3/1.png#alt=%E5%9B%BE1)\n",
    "body_draft": "---\n\n\n<a name=\"fb311eb6\"></a>\n## title: GISer的思想date: 2021-07-12 21:49:50<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.ESRI出版的《Modeling Our World》讲解了成熟的GIS思想方法<br />\n2.GIS相比传统制图工具：<br />\n• 制图工具只能在不同维度制作可视的现实还原，无法展开空间分析。GIS相当于传统制图的下一发展阶段，为整个世界创造了空间分析的可视化制图方法。值得一提的是，以CAD为代表的传统制图和GIS齐头并进，各有千秋，应当进一步融合。<br />3.分层概念：<br />\n• Feature In FeatureClass：一座城市有许多独立的、多种类的水厂，整个城市的各种水厂形成单独的群体。这就像当于面向对象中抽象的概念，各种feature继承了featureClass基类，但是feature和featureClass在GIS中都是作为独立一层存储的。<br />\n4.抽象简化：<br />\n• 空间抽象：现实信息组织入虚拟一般有抽象简化的过程，空间万物都是立体的，但是可以抽象成点线面存储在GIS中。<br />\n• 属性抽象：就像猫狗都是生物但是不同种类一般，不同的空间要素不能在同一图层，因为字段组织不一致。但是他们抽象出来的特征可能一致，即可能属于同一图层。<br />\n![](GISer%E7%9A%84%E6%80%9D%E6%83%B3/1.png#alt=%E5%9B%BE1)\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--GISer的思想-br---\ndate--2021-07-12-21-49-50-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"fb311eb6\">title: GISer的思想<br />\ndate: 2021-07-12 21:49:50<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.ESRI出版的《Modeling Our World》讲解了成熟的GIS思想方法<br />\n2.GIS相比传统制图工具：<br />\n• 制图工具只能在不同维度制作可视的现实还原，无法展开空间分析。GIS相当于传统制图的下一发展阶段，为整个世界创造了空间分析的可视化制图方法。值得一提的是，以CAD为代表的传统制图和GIS齐头并进，各有千秋，应当进一步融合。</p><p>3.分层概念：<br />\n• Feature In FeatureClass：一座城市有许多独立的、多种类的水厂，整个城市的各种水厂形成单独的群体。这就像当于面向对象中抽象的概念，各种feature继承了featureClass基类，但是feature和featureClass在GIS中都是作为独立一层存储的。<br />\n4.抽象简化：<br />\n• 空间抽象：现实信息组织入虚拟一般有抽象简化的过程，空间万物都是立体的，但是可以抽象成点线面存储在GIS中。<br />\n• 属性抽象：就像猫狗都是生物但是不同种类一般，不同的空间要素不能在同一图层，因为字段组织不一致。但是他们抽象出来的特征可能一致，即可能属于同一图层。<br />\n<img src=\"GISer%E7%9A%84%E6%80%9D%E6%83%B3/1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /></p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GISer的思想-br---\ndate--2021-07-12-21-49-50-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"fb311eb6\">title: GISer的思想<br />\ndate: 2021-07-12 21:49:50<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.ESRI出版的《Modeling Our World》讲解了成熟的GIS思想方法<br />\n2.GIS相比传统制图工具：<br />\n• 制图工具只能在不同维度制作可视的现实还原，无法展开空间分析。GIS相当于传统制图的下一发展阶段，为整个世界创造了空间分析的可视化制图方法。值得一提的是，以CAD为代表的传统制图和GIS齐头并进，各有千秋，应当进一步融合。</p><p>3.分层概念：<br />\n• Feature In FeatureClass：一座城市有许多独立的、多种类的水厂，整个城市的各种水厂形成单独的群体。这就像当于面向对象中抽象的概念，各种feature继承了featureClass基类，但是feature和featureClass在GIS中都是作为独立一层存储的。<br />\n4.抽象简化：<br />\n• 空间抽象：现实信息组织入虚拟一般有抽象简化的过程，空间万物都是立体的，但是可以抽象成点线面存储在GIS中。<br />\n• 属性抽象：就像猫狗都是生物但是不同种类一般，不同的空间要素不能在同一图层，因为字段组织不一致。但是他们抽象出来的特征可能一致，即可能属于同一图层。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22GISer%25E7%259A%2584%25E6%2580%259D%25E6%2583%25B3%2F1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card></p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GISer的思想-br---\ndate--2021-07-12-21-49-50-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"fb311eb6\">title: GISer的思想<br />\ndate: 2021-07-12 21:49:50<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.ESRI出版的《Modeling Our World》讲解了成熟的GIS思想方法<br />\n2.GIS相比传统制图工具：<br />\n• 制图工具只能在不同维度制作可视的现实还原，无法展开空间分析。GIS相当于传统制图的下一发展阶段，为整个世界创造了空间分析的可视化制图方法。值得一提的是，以CAD为代表的传统制图和GIS齐头并进，各有千秋，应当进一步融合。</p><p>3.分层概念：<br />\n• Feature In FeatureClass：一座城市有许多独立的、多种类的水厂，整个城市的各种水厂形成单独的群体。这就像当于面向对象中抽象的概念，各种feature继承了featureClass基类，但是feature和featureClass在GIS中都是作为独立一层存储的。<br />\n4.抽象简化：<br />\n• 空间抽象：现实信息组织入虚拟一般有抽象简化的过程，空间万物都是立体的，但是可以抽象成点线面存储在GIS中。<br />\n• 属性抽象：就像猫狗都是生物但是不同种类一般，不同的空间要素不能在同一图层，因为字段组织不一致。但是他们抽象出来的特征可能一致，即可能属于同一图层。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22GISer%25E7%259A%2584%25E6%2580%259D%25E6%2583%25B3%2F1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card></p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:35.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:35.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:35.000Z",
    "first_published_at": "2021-09-27T03:04:35.000Z",
    "word_count": 380,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223948,
    "slug": "skxksy",
    "title": "GIS的前沿现状",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"a0c13ee2\"></a>\n## title: GIS的前沿现状date: 2021-07-12 21:50:16<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.总体来说GIS发展遇到了瓶颈<br />\n• 烂概念+旧瓶装新酒：<br />\n○ 数字城市<br />\n○ 智慧城市<br />\n○ 城市大脑<br />\n○ CIM=BIM+GIS<br />\n○ 云GIS<br />\n○ 大数据城市<br />\n○ ……<br />\n• 大部分概念可能有一些有趣的东西，但是都不足以成为技术革命。这些名词多少有点商业包装的成分，也侧面表明了GIS产业的瓶颈。<br />2.GIS+VR/AR<br />\n• 室内导航、实景导航等如华为AR地图——河图的简单运用<br />\n![](GIS%E7%9A%84%E5%89%8D%E6%B2%BF%E7%8E%B0%E7%8A%B6/%E5%9B%BE1.png#alt=%E5%9B%BE1)\n\n3.一个研究生非常适合研究（通过）的选题：GIS+物联网+行业模型（机理模型）<br />\n• 物联网实现不难，行业模型大部分数据来源就可以利用物联网，成为数据来源；行业模型开放输入，作为静态模型存在；GIS提供背后的空间数据分析能力，最终输出时间序列或者空间序列的展示。<br />\n![](GIS%E7%9A%84%E5%89%8D%E6%B2%BF%E7%8E%B0%E7%8A%B6/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n4.GIS+大数据分析（统计学模型，和人工智能无关）<br />\n• 手机信令，北京第二次疫情病例行迹排查<br />\n5.GIS+机器学习（非机理）<br />\n• GIS科班的学生对人工智能的认识基本很模糊，机器学习的神经网络是人工智能最典型的。可以理解神经网络过程是  黑箱>>灰箱>>白箱  的过程。黑箱：未知模型>>灰箱：神经网络训练>>白箱：机理模型——可表达模型（如水动力模型数学公式）。研究这方面，训练数据和空间分析挂钩是最好，不然GIS存在感太弱。<br />\n6.RS+深度学习（非机理）<br />\n• 遥感影像解译+卷机神经网络（CNN）是天生的一对<br />\n• 栅格计算+图像识别<br />\n7.GIS+BIM<br />\n• 其实就是CIM平台开发，目前来讲做BIM的华而不实，自然CIM就是为了突破BIM的硬实力羸弱局面，但是很难，目前对于学生而言基本不现实，对于游戏开发或者大型地信企业是有用的。<br />\n8.GIS自身技术突破<br />\n• 图形学<br />\n• 三维切片（cesium），点云<br />\n• 时空GIS（停留在概念阶段）\n",
    "body_draft": "---\n\n\n<a name=\"a0c13ee2\"></a>\n## title: GIS的前沿现状date: 2021-07-12 21:50:16<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.总体来说GIS发展遇到了瓶颈<br />\n• 烂概念+旧瓶装新酒：<br />\n○ 数字城市<br />\n○ 智慧城市<br />\n○ 城市大脑<br />\n○ CIM=BIM+GIS<br />\n○ 云GIS<br />\n○ 大数据城市<br />\n○ ……<br />\n• 大部分概念可能有一些有趣的东西，但是都不足以成为技术革命。这些名词多少有点商业包装的成分，也侧面表明了GIS产业的瓶颈。<br />2.GIS+VR/AR<br />\n• 室内导航、实景导航等如华为AR地图——河图的简单运用<br />\n![](GIS%E7%9A%84%E5%89%8D%E6%B2%BF%E7%8E%B0%E7%8A%B6/%E5%9B%BE1.png#alt=%E5%9B%BE1)\n\n3.一个研究生非常适合研究（通过）的选题：GIS+物联网+行业模型（机理模型）<br />\n• 物联网实现不难，行业模型大部分数据来源就可以利用物联网，成为数据来源；行业模型开放输入，作为静态模型存在；GIS提供背后的空间数据分析能力，最终输出时间序列或者空间序列的展示。<br />\n![](GIS%E7%9A%84%E5%89%8D%E6%B2%BF%E7%8E%B0%E7%8A%B6/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n4.GIS+大数据分析（统计学模型，和人工智能无关）<br />\n• 手机信令，北京第二次疫情病例行迹排查<br />\n5.GIS+机器学习（非机理）<br />\n• GIS科班的学生对人工智能的认识基本很模糊，机器学习的神经网络是人工智能最典型的。可以理解神经网络过程是  黑箱>>灰箱>>白箱  的过程。黑箱：未知模型>>灰箱：神经网络训练>>白箱：机理模型——可表达模型（如水动力模型数学公式）。研究这方面，训练数据和空间分析挂钩是最好，不然GIS存在感太弱。<br />\n6.RS+深度学习（非机理）<br />\n• 遥感影像解译+卷机神经网络（CNN）是天生的一对<br />\n• 栅格计算+图像识别<br />\n7.GIS+BIM<br />\n• 其实就是CIM平台开发，目前来讲做BIM的华而不实，自然CIM就是为了突破BIM的硬实力羸弱局面，但是很难，目前对于学生而言基本不现实，对于游戏开发或者大型地信企业是有用的。<br />\n8.GIS自身技术突破<br />\n• 图形学<br />\n• 三维切片（cesium），点云<br />\n• 时空GIS（停留在概念阶段）\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--GIS的前沿现状-br---\ndate--2021-07-12-21-50-16-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"a0c13ee2\">title: GIS的前沿现状<br />\ndate: 2021-07-12 21:50:16<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.总体来说GIS发展遇到了瓶颈<br />\n• 烂概念+旧瓶装新酒：<br />\n○ 数字城市<br />\n○ 智慧城市<br />\n○ 城市大脑<br />\n○ CIM=BIM+GIS<br />\n○ 云GIS<br />\n○ 大数据城市<br />\n○ ……<br />\n• 大部分概念可能有一些有趣的东西，但是都不足以成为技术革命。这些名词多少有点商业包装的成分，也侧面表明了GIS产业的瓶颈。</p><p>2.GIS+VR/AR<br />\n• 室内导航、实景导航等如华为AR地图——河图的简单运用<br />\n<img src=\"GIS%E7%9A%84%E5%89%8D%E6%B2%BF%E7%8E%B0%E7%8A%B6/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /></p><p><br /></p><p>3.一个研究生非常适合研究（通过）的选题：GIS+物联网+行业模型（机理模型）<br />\n• 物联网实现不难，行业模型大部分数据来源就可以利用物联网，成为数据来源；行业模型开放输入，作为静态模型存在；GIS提供背后的空间数据分析能力，最终输出时间序列或者空间序列的展示。<br />\n<img src=\"GIS%E7%9A%84%E5%89%8D%E6%B2%BF%E7%8E%B0%E7%8A%B6/%E5%9B%BE2.png#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n4.GIS+大数据分析（统计学模型，和人工智能无关）<br />\n• 手机信令，北京第二次疫情病例行迹排查<br />\n5.GIS+机器学习（非机理）<br />\n• GIS科班的学生对人工智能的认识基本很模糊，机器学习的神经网络是人工智能最典型的。可以理解神经网络过程是  黑箱&gt;&gt;灰箱&gt;&gt;白箱  的过程。黑箱：未知模型&gt;&gt;灰箱：神经网络训练&gt;&gt;白箱：机理模型——可表达模型（如水动力模型数学公式）。研究这方面，训练数据和空间分析挂钩是最好，不然GIS存在感太弱。<br />\n6.RS+深度学习（非机理）<br />\n• 遥感影像解译+卷机神经网络（CNN）是天生的一对<br />\n• 栅格计算+图像识别<br />\n7.GIS+BIM<br />\n• 其实就是CIM平台开发，目前来讲做BIM的华而不实，自然CIM就是为了突破BIM的硬实力羸弱局面，但是很难，目前对于学生而言基本不现实，对于游戏开发或者大型地信企业是有用的。<br />\n8.GIS自身技术突破<br />\n• 图形学<br />\n• 三维切片（cesium），点云<br />\n• 时空GIS（停留在概念阶段）</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GIS的前沿现状-br---\ndate--2021-07-12-21-50-16-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"a0c13ee2\">title: GIS的前沿现状<br />\ndate: 2021-07-12 21:50:16<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.总体来说GIS发展遇到了瓶颈<br />\n• 烂概念+旧瓶装新酒：<br />\n○ 数字城市<br />\n○ 智慧城市<br />\n○ 城市大脑<br />\n○ CIM=BIM+GIS<br />\n○ 云GIS<br />\n○ 大数据城市<br />\n○ ……<br />\n• 大部分概念可能有一些有趣的东西，但是都不足以成为技术革命。这些名词多少有点商业包装的成分，也侧面表明了GIS产业的瓶颈。</p><p>2.GIS+VR/AR<br />\n• 室内导航、实景导航等如华为AR地图——河图的简单运用<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22GIS%25E7%259A%2584%25E5%2589%258D%25E6%25B2%25BF%25E7%258E%25B0%25E7%258A%25B6%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card></p><p><br /></p><p>3.一个研究生非常适合研究（通过）的选题：GIS+物联网+行业模型（机理模型）<br />\n• 物联网实现不难，行业模型大部分数据来源就可以利用物联网，成为数据来源；行业模型开放输入，作为静态模型存在；GIS提供背后的空间数据分析能力，最终输出时间序列或者空间序列的展示。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22GIS%25E7%259A%2584%25E5%2589%258D%25E6%25B2%25BF%25E7%258E%25B0%25E7%258A%25B6%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n4.GIS+大数据分析（统计学模型，和人工智能无关）<br />\n• 手机信令，北京第二次疫情病例行迹排查<br />\n5.GIS+机器学习（非机理）<br />\n• GIS科班的学生对人工智能的认识基本很模糊，机器学习的神经网络是人工智能最典型的。可以理解神经网络过程是  黑箱&gt;&gt;灰箱&gt;&gt;白箱  的过程。黑箱：未知模型&gt;&gt;灰箱：神经网络训练&gt;&gt;白箱：机理模型——可表达模型（如水动力模型数学公式）。研究这方面，训练数据和空间分析挂钩是最好，不然GIS存在感太弱。<br />\n6.RS+深度学习（非机理）<br />\n• 遥感影像解译+卷机神经网络（CNN）是天生的一对<br />\n• 栅格计算+图像识别<br />\n7.GIS+BIM<br />\n• 其实就是CIM平台开发，目前来讲做BIM的华而不实，自然CIM就是为了突破BIM的硬实力羸弱局面，但是很难，目前对于学生而言基本不现实，对于游戏开发或者大型地信企业是有用的。<br />\n8.GIS自身技术突破<br />\n• 图形学<br />\n• 三维切片（cesium），点云<br />\n• 时空GIS（停留在概念阶段）</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GIS的前沿现状-br---\ndate--2021-07-12-21-50-16-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"a0c13ee2\">title: GIS的前沿现状<br />\ndate: 2021-07-12 21:50:16<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.总体来说GIS发展遇到了瓶颈<br />\n• 烂概念+旧瓶装新酒：<br />\n○ 数字城市<br />\n○ 智慧城市<br />\n○ 城市大脑<br />\n○ CIM=BIM+GIS<br />\n○ 云GIS<br />\n○ 大数据城市<br />\n○ ……<br />\n• 大部分概念可能有一些有趣的东西，但是都不足以成为技术革命。这些名词多少有点商业包装的成分，也侧面表明了GIS产业的瓶颈。</p><p>2.GIS+VR/AR<br />\n• 室内导航、实景导航等如华为AR地图——河图的简单运用<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22GIS%25E7%259A%2584%25E5%2589%258D%25E6%25B2%25BF%25E7%258E%25B0%25E7%258A%25B6%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card></p><p><br /></p><p>3.一个研究生非常适合研究（通过）的选题：GIS+物联网+行业模型（机理模型）<br />\n• 物联网实现不难，行业模型大部分数据来源就可以利用物联网，成为数据来源；行业模型开放输入，作为静态模型存在；GIS提供背后的空间数据分析能力，最终输出时间序列或者空间序列的展示。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22GIS%25E7%259A%2584%25E5%2589%258D%25E6%25B2%25BF%25E7%258E%25B0%25E7%258A%25B6%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n4.GIS+大数据分析（统计学模型，和人工智能无关）<br />\n• 手机信令，北京第二次疫情病例行迹排查<br />\n5.GIS+机器学习（非机理）<br />\n• GIS科班的学生对人工智能的认识基本很模糊，机器学习的神经网络是人工智能最典型的。可以理解神经网络过程是  黑箱&gt;&gt;灰箱&gt;&gt;白箱  的过程。黑箱：未知模型&gt;&gt;灰箱：神经网络训练&gt;&gt;白箱：机理模型——可表达模型（如水动力模型数学公式）。研究这方面，训练数据和空间分析挂钩是最好，不然GIS存在感太弱。<br />\n6.RS+深度学习（非机理）<br />\n• 遥感影像解译+卷机神经网络（CNN）是天生的一对<br />\n• 栅格计算+图像识别<br />\n7.GIS+BIM<br />\n• 其实就是CIM平台开发，目前来讲做BIM的华而不实，自然CIM就是为了突破BIM的硬实力羸弱局面，但是很难，目前对于学生而言基本不现实，对于游戏开发或者大型地信企业是有用的。<br />\n8.GIS自身技术突破<br />\n• 图形学<br />\n• 三维切片（cesium），点云<br />\n• 时空GIS（停留在概念阶段）</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:30.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:30.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:30.000Z",
    "first_published_at": "2021-09-27T03:04:30.000Z",
    "word_count": 631,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223937,
    "slug": "wgc27n",
    "title": "GIS的简要定义",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"a595c6c1\"></a>\n## title: GIS的简要定义date: 2021-07-12 21:49:33<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.GIS的四层定义：<br />\n• 第一层面，表现层（最直观的，非科班出身的理解），就是一张地图的可视化；<br />\n• 第二层面，应用层（最对口的，接触最多的领域），是一类软件，集合了对地理要素的编辑查询分析等功能；<br />\n• 第三层面，服务层（最近走入人们的视野），读取地图数据后，提供一系列API，面向开发者和最终用户提供数据处理、数据分析、数据发布等服务包；<br />\n• 第四层面，数据层，GIS主要的两个数据类型：矢量和栅格；这两个数据类型又有多种格式如SHP、GDB、GRID等。这一层体现了GIS的数据结构以及存储方式。<br />2.关于：<br />\n• 从第一层到第四层GIS的认识是逐步加深的，GIS作为一个系统，用于建模（modeling our world）人类认知的世界中的地理要素，存在着从现实到虚拟的概要简化，作为矢量格式或者栅格格式存储。将一系列底层功能如数据处理、数据分析、数据发布的代码整合到API发布给开发者，最后开发者包装数据编辑、查询、分析等功能形成软件平台提供给用户，数据最终都转换为数字化地图。\n",
    "body_draft": "---\n\n\n<a name=\"a595c6c1\"></a>\n## title: GIS的简要定义date: 2021-07-12 21:49:33<br />tags: [GIS, GISer, 思想]<br />categories: 地信原理特辑\n\n1.GIS的四层定义：<br />\n• 第一层面，表现层（最直观的，非科班出身的理解），就是一张地图的可视化；<br />\n• 第二层面，应用层（最对口的，接触最多的领域），是一类软件，集合了对地理要素的编辑查询分析等功能；<br />\n• 第三层面，服务层（最近走入人们的视野），读取地图数据后，提供一系列API，面向开发者和最终用户提供数据处理、数据分析、数据发布等服务包；<br />\n• 第四层面，数据层，GIS主要的两个数据类型：矢量和栅格；这两个数据类型又有多种格式如SHP、GDB、GRID等。这一层体现了GIS的数据结构以及存储方式。<br />2.关于：<br />\n• 从第一层到第四层GIS的认识是逐步加深的，GIS作为一个系统，用于建模（modeling our world）人类认知的世界中的地理要素，存在着从现实到虚拟的概要简化，作为矢量格式或者栅格格式存储。将一系列底层功能如数据处理、数据分析、数据发布的代码整合到API发布给开发者，最后开发者包装数据编辑、查询、分析等功能形成软件平台提供给用户，数据最终都转换为数字化地图。\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--GIS的简要定义-br---\ndate--2021-07-12-21-49-33-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"a595c6c1\">title: GIS的简要定义<br />\ndate: 2021-07-12 21:49:33<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.GIS的四层定义：<br />\n• 第一层面，表现层（最直观的，非科班出身的理解），就是一张地图的可视化；<br />\n• 第二层面，应用层（最对口的，接触最多的领域），是一类软件，集合了对地理要素的编辑查询分析等功能；<br />\n• 第三层面，服务层（最近走入人们的视野），读取地图数据后，提供一系列API，面向开发者和最终用户提供数据处理、数据分析、数据发布等服务包；<br />\n• 第四层面，数据层，GIS主要的两个数据类型：矢量和栅格；这两个数据类型又有多种格式如SHP、GDB、GRID等。这一层体现了GIS的数据结构以及存储方式。</p><p>2.关于：<br />\n• 从第一层到第四层GIS的认识是逐步加深的，GIS作为一个系统，用于建模（modeling our world）人类认知的世界中的地理要素，存在着从现实到虚拟的概要简化，作为矢量格式或者栅格格式存储。将一系列底层功能如数据处理、数据分析、数据发布的代码整合到API发布给开发者，最后开发者包装数据编辑、查询、分析等功能形成软件平台提供给用户，数据最终都转换为数字化地图。</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GIS的简要定义-br---\ndate--2021-07-12-21-49-33-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"a595c6c1\">title: GIS的简要定义<br />\ndate: 2021-07-12 21:49:33<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.GIS的四层定义：<br />\n• 第一层面，表现层（最直观的，非科班出身的理解），就是一张地图的可视化；<br />\n• 第二层面，应用层（最对口的，接触最多的领域），是一类软件，集合了对地理要素的编辑查询分析等功能；<br />\n• 第三层面，服务层（最近走入人们的视野），读取地图数据后，提供一系列API，面向开发者和最终用户提供数据处理、数据分析、数据发布等服务包；<br />\n• 第四层面，数据层，GIS主要的两个数据类型：矢量和栅格；这两个数据类型又有多种格式如SHP、GDB、GRID等。这一层体现了GIS的数据结构以及存储方式。</p><p>2.关于：<br />\n• 从第一层到第四层GIS的认识是逐步加深的，GIS作为一个系统，用于建模（modeling our world）人类认知的世界中的地理要素，存在着从现实到虚拟的概要简化，作为矢量格式或者栅格格式存储。将一系列底层功能如数据处理、数据分析、数据发布的代码整合到API发布给开发者，最后开发者包装数据编辑、查询、分析等功能形成软件平台提供给用户，数据最终都转换为数字化地图。</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--GIS的简要定义-br---\ndate--2021-07-12-21-49-33-br---\ntags--[GIS--GISer--思想]-br---\ncategories--地信原理特辑\"></a><h2 id=\"a595c6c1\">title: GIS的简要定义<br />\ndate: 2021-07-12 21:49:33<br />\ntags: [GIS, GISer, 思想]<br />\ncategories: 地信原理特辑</h2><p><br /></p><p>1.GIS的四层定义：<br />\n• 第一层面，表现层（最直观的，非科班出身的理解），就是一张地图的可视化；<br />\n• 第二层面，应用层（最对口的，接触最多的领域），是一类软件，集合了对地理要素的编辑查询分析等功能；<br />\n• 第三层面，服务层（最近走入人们的视野），读取地图数据后，提供一系列API，面向开发者和最终用户提供数据处理、数据分析、数据发布等服务包；<br />\n• 第四层面，数据层，GIS主要的两个数据类型：矢量和栅格；这两个数据类型又有多种格式如SHP、GDB、GRID等。这一层体现了GIS的数据结构以及存储方式。</p><p>2.关于：<br />\n• 从第一层到第四层GIS的认识是逐步加深的，GIS作为一个系统，用于建模（modeling our world）人类认知的世界中的地理要素，存在着从现实到虚拟的概要简化，作为矢量格式或者栅格格式存储。将一系列底层功能如数据处理、数据分析、数据发布的代码整合到API发布给开发者，最后开发者包装数据编辑、查询、分析等功能形成软件平台提供给用户，数据最终都转换为数字化地图。</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:25.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:25.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:25.000Z",
    "first_published_at": "2021-09-27T03:04:25.000Z",
    "word_count": 417,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223929,
    "slug": "pklxqf",
    "title": "Anaconda环境日志",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"a19d9bc1\"></a>\n## title: Anaconda环境日志date: 2021-08-07 22:08:11<br />tags: [深度学习, 语义分割, Anaconda, Python]<br />categories: 计算机视觉特辑\n\n1.创建虚拟环境<br />\n• conda create -n your_env_name python=X.X<br />\n2.更新conda（慎用！！！，新conda可能用不了）<br />\n• conda updata conda<br />\n3.查看虚拟环境菜单和环境内已载入库<br />\n• conda env list/conda info -e<br />\n• conda list<br />4.激活虚拟环境<br />\n• Conda activate your_env_name<br />\n5.前人配置好的版本<br />\n• Keras2.2.4<br />\n• Tensorflow-gpu1.12.0<br />\n6.如果遇到conda安装频繁报错，使用如下语句：<br />\n• conda clean -i<br />\n7.如果不幸要删除虚拟环境<br />\n• conda remove -n your_env_name --all<br />\n8.如果pip安装报错如下，可以检查一下是不是翻墙了<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n9.镜像pip<br />\n• pip install -i [https://pypi.tuna.tsinghua.edu.cn/simple](https://pypi.tuna.tsinghua.edu.cn/simple) opencv-python<br />\n• pip install -i [https://pypi.douban.com/simple](https://pypi.douban.com/simple) opencv-python\n\n10.大电脑虚拟环境记录：<br />\n• Main5：keras开发框架<br />\n• labelme：用于打开labelme工具<br />\n• torch：Torch开发框架\n\n⚠️tensorflow、keras、python对应版本关系：<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n⚠️Tensorflow、CUDA、python、cudnn版本关系：<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n⚠️前人配置环境全赏:<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE4.jpg#alt=%E5%9B%BE4)\n",
    "body_draft": "---\n\n\n<a name=\"a19d9bc1\"></a>\n## title: Anaconda环境日志date: 2021-08-07 22:08:11<br />tags: [深度学习, 语义分割, Anaconda, Python]<br />categories: 计算机视觉特辑\n\n1.创建虚拟环境<br />\n• conda create -n your_env_name python=X.X<br />\n2.更新conda（慎用！！！，新conda可能用不了）<br />\n• conda updata conda<br />\n3.查看虚拟环境菜单和环境内已载入库<br />\n• conda env list/conda info -e<br />\n• conda list<br />4.激活虚拟环境<br />\n• Conda activate your_env_name<br />\n5.前人配置好的版本<br />\n• Keras2.2.4<br />\n• Tensorflow-gpu1.12.0<br />\n6.如果遇到conda安装频繁报错，使用如下语句：<br />\n• conda clean -i<br />\n7.如果不幸要删除虚拟环境<br />\n• conda remove -n your_env_name --all<br />\n8.如果pip安装报错如下，可以检查一下是不是翻墙了<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n9.镜像pip<br />\n• pip install -i [https://pypi.tuna.tsinghua.edu.cn/simple](https://pypi.tuna.tsinghua.edu.cn/simple) opencv-python<br />\n• pip install -i [https://pypi.douban.com/simple](https://pypi.douban.com/simple) opencv-python\n\n10.大电脑虚拟环境记录：<br />\n• Main5：keras开发框架<br />\n• labelme：用于打开labelme工具<br />\n• torch：Torch开发框架\n\n⚠️tensorflow、keras、python对应版本关系：<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n⚠️Tensorflow、CUDA、python、cudnn版本关系：<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n⚠️前人配置环境全赏:<br />\n![](Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE4.jpg#alt=%E5%9B%BE4)\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--Anaconda环境日志-br---\ndate--2021-08-07-22-08-11-br---\ntags--[深度学习--语义分割--Anaconda--Python]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"a19d9bc1\">title: Anaconda环境日志<br />\ndate: 2021-08-07 22:08:11<br />\ntags: [深度学习, 语义分割, Anaconda, Python]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.创建虚拟环境<br />\n• conda create -n your_env_name python=X.X<br />\n2.更新conda（慎用！！！，新conda可能用不了）<br />\n• conda updata conda<br />\n3.查看虚拟环境菜单和环境内已载入库<br />\n• conda env list/conda info -e<br />\n• conda list</p><p>4.激活虚拟环境<br />\n• Conda activate your_env_name<br />\n5.前人配置好的版本<br />\n• Keras<mark>2.2.4<br />\n• Tensorflow-gpu</mark>1.12.0<br />\n6.如果遇到conda安装频繁报错，使用如下语句：<br />\n• conda clean -i<br />\n7.如果不幸要删除虚拟环境<br />\n• conda remove -n your_env_name --all<br />\n8.如果pip安装报错如下，可以检查一下是不是翻墙了<br />\n<img src=\"Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n9.镜像pip<br />\n• pip install -i <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\">https://pypi.tuna.tsinghua.edu.cn/simple</a> opencv-python<br />\n• pip install -i <a href=\"https://pypi.douban.com/simple\" target=\"_blank\">https://pypi.douban.com/simple</a> opencv-python</p><p><br /></p><p>10.大电脑虚拟环境记录：<br />\n• Main5：keras开发框架<br />\n• labelme：用于打开labelme工具<br />\n• torch：Torch开发框架</p><p><br /></p><p>⚠️tensorflow、keras、python对应版本关系：<br />\n<img src=\"Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE2.png#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n⚠️Tensorflow、CUDA、python、cudnn版本关系：<br />\n<img src=\"Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE3.png#alt=%E5%9B%BE3\" style=\"max-width: 600px;\" /><br />\n⚠️前人配置环境全赏:<br />\n<img src=\"Anaconda%E7%8E%AF%E5%A2%83%E6%97%A5%E5%BF%97/%E5%9B%BE4.jpg#alt=%E5%9B%BE4\" style=\"max-width: 600px;\" /></p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Anaconda环境日志-br---\ndate--2021-08-07-22-08-11-br---\ntags--[深度学习--语义分割--Anaconda--Python]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"a19d9bc1\">title: Anaconda环境日志<br />\ndate: 2021-08-07 22:08:11<br />\ntags: [深度学习, 语义分割, Anaconda, Python]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.创建虚拟环境<br />\n• conda create -n your_env_name python=X.X<br />\n2.更新conda（慎用！！！，新conda可能用不了）<br />\n• conda updata conda<br />\n3.查看虚拟环境菜单和环境内已载入库<br />\n• conda env list/conda info -e<br />\n• conda list</p><p>4.激活虚拟环境<br />\n• Conda activate your_env_name<br />\n5.前人配置好的版本<br />\n• Keras<mark>2.2.4<br />\n• Tensorflow-gpu</mark>1.12.0<br />\n6.如果遇到conda安装频繁报错，使用如下语句：<br />\n• conda clean -i<br />\n7.如果不幸要删除虚拟环境<br />\n• conda remove -n your_env_name --all<br />\n8.如果pip安装报错如下，可以检查一下是不是翻墙了<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n9.镜像pip<br />\n• pip install -i <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\">https://pypi.tuna.tsinghua.edu.cn/simple</a> opencv-python<br />\n• pip install -i <a href=\"https://pypi.douban.com/simple\" target=\"_blank\">https://pypi.douban.com/simple</a> opencv-python</p><p><br /></p><p>10.大电脑虚拟环境记录：<br />\n• Main5：keras开发框架<br />\n• labelme：用于打开labelme工具<br />\n• torch：Torch开发框架</p><p><br /></p><p>⚠️tensorflow、keras、python对应版本关系：<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n⚠️Tensorflow、CUDA、python、cudnn版本关系：<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n⚠️前人配置环境全赏:<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE4.jpg%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card></p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--Anaconda环境日志-br---\ndate--2021-08-07-22-08-11-br---\ntags--[深度学习--语义分割--Anaconda--Python]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"a19d9bc1\">title: Anaconda环境日志<br />\ndate: 2021-08-07 22:08:11<br />\ntags: [深度学习, 语义分割, Anaconda, Python]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.创建虚拟环境<br />\n• conda create -n your_env_name python=X.X<br />\n2.更新conda（慎用！！！，新conda可能用不了）<br />\n• conda updata conda<br />\n3.查看虚拟环境菜单和环境内已载入库<br />\n• conda env list/conda info -e<br />\n• conda list</p><p>4.激活虚拟环境<br />\n• Conda activate your_env_name<br />\n5.前人配置好的版本<br />\n• Keras<mark>2.2.4<br />\n• Tensorflow-gpu</mark>1.12.0<br />\n6.如果遇到conda安装频繁报错，使用如下语句：<br />\n• conda clean -i<br />\n7.如果不幸要删除虚拟环境<br />\n• conda remove -n your_env_name --all<br />\n8.如果pip安装报错如下，可以检查一下是不是翻墙了<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n9.镜像pip<br />\n• pip install -i <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple\" target=\"_blank\">https://pypi.tuna.tsinghua.edu.cn/simple</a> opencv-python<br />\n• pip install -i <a href=\"https://pypi.douban.com/simple\" target=\"_blank\">https://pypi.douban.com/simple</a> opencv-python</p><p><br /></p><p>10.大电脑虚拟环境记录：<br />\n• Main5：keras开发框架<br />\n• labelme：用于打开labelme工具<br />\n• torch：Torch开发框架</p><p><br /></p><p>⚠️tensorflow、keras、python对应版本关系：<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n⚠️Tensorflow、CUDA、python、cudnn版本关系：<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n⚠️前人配置环境全赏:<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22Anaconda%25E7%258E%25AF%25E5%25A2%2583%25E6%2597%25A5%25E5%25BF%2597%2F%25E5%259B%25BE4.jpg%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card></p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:20.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:20.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:20.000Z",
    "first_published_at": "2021-09-27T03:04:20.000Z",
    "word_count": 272,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223917,
    "slug": "ot04dg",
    "title": "损失函数与语义分割任务",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"6a1f818a\"></a>\n## title: 损失函数与语义分割任务date: 2021-08-07 22:29:17<br />tags: [深度学习, 语义分割]<br />categories: 计算机视觉特辑\n\n1.基于分布的损失函数，基于区域的损失函数，基于边界的损失函数和基于复合的损失函数（ Distribution-based,Region-based,  Boundary-based,  and  Compounded）<br />![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n2.分类标签不平衡问题：<br />\n• 道路识别中，数据集拥有的正样本非常少，有时候背景负样本带来很多没必要的损失函数值的参数更新，类似噪声干扰了正样本训练，无论双分类训练还是多分类训练都存在该问题，更不用说多分类任务。<br />\n• 解决方案<br />\n损失函数本身对训练影响弱于数据集，但是，如果数据集中标签严重不平衡，还是应该选择二进制交叉熵(binary-cross entropy)之外的其他损失函数，如DiceLoss系列。<br />\n○ 普通DiceLoss损失函数<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n上面公式比较通俗，右侧部分称Dice系数（dice coefficient），由1减去就得到了DiceLoss。对于分割任务而言，绝对值X和Y分别代表ground_truth和predict_mask。一般和IoU一样作为测试的评价指数，实际训练效果非常糟糕。<br />\n○ Log-Cosh Dice Loss<br />\n普通DiceLoss由于其非凸性，它多次都无法获得最佳结果。Lovsz-softmax损失旨在通过添加使用Lovsz扩展的平滑来解决非凸损失函数的问题。同时，Log-Cosh方法已广泛用于基于回归的问题中，以平滑曲线。<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n但是该损失函数无法在我的项目中运行（ExpLog_Dice）<br />\n○ Tversky Loss<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\nTversky系数是Dice系数和 Jaccard 系数的一种推广。当设置α=β=0.5，此时Tversky系数就是Dice系数。而当设置α=β=1时，此时Tversky系数就是Jaccard系数。α和β分别控制假阴性和假阳性。通过调整α和β，可以控制假阳性和假阴性之间的平衡。<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n○ Focal Tversky Loss<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE7.png#alt=%E5%9B%BE7)\n\n参考文章： Loss Functions for Medical Image Segmentation: A Taxonomy | by JunMa | Medium [https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized Dice loss is the multi-class extension of,negatives and false positives in generalized Dice loss](https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized%20Dice%20loss%20is%20the%20multi-class%20extension%20of,negatives%20and%20false%20positives%20in%20generalized%20Dice%20loss).<br />\nGitHub： GitHub - JunMa11/SegLoss: A collection of loss functions for medical image segmentation [https://github.com/JunMa11/SegLoss](https://github.com/JunMa11/SegLoss)<br />\n论文：[https://arxiv.org/pdf/2006.14822.pdf](https://arxiv.org/pdf/2006.14822.pdf)\n",
    "body_draft": "---\n\n\n<a name=\"6a1f818a\"></a>\n## title: 损失函数与语义分割任务date: 2021-08-07 22:29:17<br />tags: [深度学习, 语义分割]<br />categories: 计算机视觉特辑\n\n1.基于分布的损失函数，基于区域的损失函数，基于边界的损失函数和基于复合的损失函数（ Distribution-based,Region-based,  Boundary-based,  and  Compounded）<br />![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE1.png#alt=%E5%9B%BE1)<br />\n2.分类标签不平衡问题：<br />\n• 道路识别中，数据集拥有的正样本非常少，有时候背景负样本带来很多没必要的损失函数值的参数更新，类似噪声干扰了正样本训练，无论双分类训练还是多分类训练都存在该问题，更不用说多分类任务。<br />\n• 解决方案<br />\n损失函数本身对训练影响弱于数据集，但是，如果数据集中标签严重不平衡，还是应该选择二进制交叉熵(binary-cross entropy)之外的其他损失函数，如DiceLoss系列。<br />\n○ 普通DiceLoss损失函数<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE2.png#alt=%E5%9B%BE2)<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE3.png#alt=%E5%9B%BE3)<br />\n上面公式比较通俗，右侧部分称Dice系数（dice coefficient），由1减去就得到了DiceLoss。对于分割任务而言，绝对值X和Y分别代表ground_truth和predict_mask。一般和IoU一样作为测试的评价指数，实际训练效果非常糟糕。<br />\n○ Log-Cosh Dice Loss<br />\n普通DiceLoss由于其非凸性，它多次都无法获得最佳结果。Lovsz-softmax损失旨在通过添加使用Lovsz扩展的平滑来解决非凸损失函数的问题。同时，Log-Cosh方法已广泛用于基于回归的问题中，以平滑曲线。<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE4.png#alt=%E5%9B%BE4)<br />\n但是该损失函数无法在我的项目中运行（ExpLog_Dice）<br />\n○ Tversky Loss<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE5.png#alt=%E5%9B%BE5)<br />\nTversky系数是Dice系数和 Jaccard 系数的一种推广。当设置α=β=0.5，此时Tversky系数就是Dice系数。而当设置α=β=1时，此时Tversky系数就是Jaccard系数。α和β分别控制假阴性和假阳性。通过调整α和β，可以控制假阳性和假阴性之间的平衡。<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE6.png#alt=%E5%9B%BE6)<br />\n○ Focal Tversky Loss<br />\n![](%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE7.png#alt=%E5%9B%BE7)\n\n参考文章： Loss Functions for Medical Image Segmentation: A Taxonomy | by JunMa | Medium [https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized Dice loss is the multi-class extension of,negatives and false positives in generalized Dice loss](https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized%20Dice%20loss%20is%20the%20multi-class%20extension%20of,negatives%20and%20false%20positives%20in%20generalized%20Dice%20loss).<br />\nGitHub： GitHub - JunMa11/SegLoss: A collection of loss functions for medical image segmentation [https://github.com/JunMa11/SegLoss](https://github.com/JunMa11/SegLoss)<br />\n论文：[https://arxiv.org/pdf/2006.14822.pdf](https://arxiv.org/pdf/2006.14822.pdf)\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--损失函数与语义分割任务-br---\ndate--2021-08-07-22-29-17-br---\ntags--[深度学习--语义分割]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"6a1f818a\">title: 损失函数与语义分割任务<br />\ndate: 2021-08-07 22:29:17<br />\ntags: [深度学习, 语义分割]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.基于分布的损失函数，基于区域的损失函数，基于边界的损失函数和基于复合的损失函数（ Distribution-based,Region-based,  Boundary-based,  and  Compounded）</p><p><img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n2.分类标签不平衡问题：<br />\n• 道路识别中，数据集拥有的正样本非常少，有时候背景负样本带来很多没必要的损失函数值的参数更新，类似噪声干扰了正样本训练，无论双分类训练还是多分类训练都存在该问题，更不用说多分类任务。<br />\n• 解决方案<br />\n损失函数本身对训练影响弱于数据集，但是，如果数据集中标签严重不平衡，还是应该选择二进制交叉熵(binary-cross entropy)之外的其他损失函数，如DiceLoss系列。<br />\n○ 普通DiceLoss损失函数<br />\n<img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE2.png#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n<img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE3.png#alt=%E5%9B%BE3\" style=\"max-width: 600px;\" /><br />\n上面公式比较通俗，右侧部分称Dice系数（dice coefficient），由1减去就得到了DiceLoss。对于分割任务而言，绝对值X和Y分别代表ground_truth和predict_mask。一般和IoU一样作为测试的评价指数，实际训练效果非常糟糕。<br />\n○ Log-Cosh Dice Loss<br />\n普通DiceLoss由于其非凸性，它多次都无法获得最佳结果。Lovsz-softmax损失旨在通过添加使用Lovsz扩展的平滑来解决非凸损失函数的问题。同时，Log-Cosh方法已广泛用于基于回归的问题中，以平滑曲线。<br />\n<img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE4.png#alt=%E5%9B%BE4\" style=\"max-width: 600px;\" /><br />\n但是该损失函数无法在我的项目中运行（ExpLog_Dice）<br />\n○ Tversky Loss<br />\n<img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE5.png#alt=%E5%9B%BE5\" style=\"max-width: 600px;\" /><br />\nTversky系数是Dice系数和 Jaccard 系数的一种推广。当设置α=β=0.5，此时Tversky系数就是Dice系数。而当设置α=β=1时，此时Tversky系数就是Jaccard系数。α和β分别控制假阴性和假阳性。通过调整α和β，可以控制假阳性和假阴性之间的平衡。<br />\n<img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE6.png#alt=%E5%9B%BE6\" style=\"max-width: 600px;\" /><br />\n○ Focal Tversky Loss<br />\n<img src=\"%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1/%E5%9B%BE7.png#alt=%E5%9B%BE7\" style=\"max-width: 600px;\" /></p><p><br /></p><p>参考文章： Loss Functions for Medical Image Segmentation: A Taxonomy | by JunMa | Medium <a href=\"https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized%20Dice%20loss%20is%20the%20multi-class%20extension%20of,negatives%20and%20false%20positives%20in%20generalized%20Dice%20loss\" target=\"_blank\">https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized Dice loss is the multi-class extension of,negatives and false positives in generalized Dice loss</a>.<br />\nGitHub： GitHub - JunMa11/SegLoss: A collection of loss functions for medical image segmentation <a href=\"https://github.com/JunMa11/SegLoss\" target=\"_blank\">https://github.com/JunMa11/SegLoss</a><br />\n论文：<a href=\"https://arxiv.org/pdf/2006.14822.pdf\" target=\"_blank\">https://arxiv.org/pdf/2006.14822.pdf</a></p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--损失函数与语义分割任务-br---\ndate--2021-08-07-22-29-17-br---\ntags--[深度学习--语义分割]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"6a1f818a\">title: 损失函数与语义分割任务<br />\ndate: 2021-08-07 22:29:17<br />\ntags: [深度学习, 语义分割]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.基于分布的损失函数，基于区域的损失函数，基于边界的损失函数和基于复合的损失函数（ Distribution-based,Region-based,  Boundary-based,  and  Compounded）</p><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n2.分类标签不平衡问题：<br />\n• 道路识别中，数据集拥有的正样本非常少，有时候背景负样本带来很多没必要的损失函数值的参数更新，类似噪声干扰了正样本训练，无论双分类训练还是多分类训练都存在该问题，更不用说多分类任务。<br />\n• 解决方案<br />\n损失函数本身对训练影响弱于数据集，但是，如果数据集中标签严重不平衡，还是应该选择二进制交叉熵(binary-cross entropy)之外的其他损失函数，如DiceLoss系列。<br />\n○ 普通DiceLoss损失函数<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n上面公式比较通俗，右侧部分称Dice系数（dice coefficient），由1减去就得到了DiceLoss。对于分割任务而言，绝对值X和Y分别代表ground_truth和predict_mask。一般和IoU一样作为测试的评价指数，实际训练效果非常糟糕。<br />\n○ Log-Cosh Dice Loss<br />\n普通DiceLoss由于其非凸性，它多次都无法获得最佳结果。Lovsz-softmax损失旨在通过添加使用Lovsz扩展的平滑来解决非凸损失函数的问题。同时，Log-Cosh方法已广泛用于基于回归的问题中，以平滑曲线。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n但是该损失函数无法在我的项目中运行（ExpLog_Dice）<br />\n○ Tversky Loss<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\nTversky系数是Dice系数和 Jaccard 系数的一种推广。当设置α=β=0.5，此时Tversky系数就是Dice系数。而当设置α=β=1时，此时Tversky系数就是Jaccard系数。α和β分别控制假阴性和假阳性。通过调整α和β，可以控制假阳性和假阴性之间的平衡。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n○ Focal Tversky Loss<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card></p><p><br /></p><p>参考文章： Loss Functions for Medical Image Segmentation: A Taxonomy | by JunMa | Medium <a href=\"https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized%20Dice%20loss%20is%20the%20multi-class%20extension%20of,negatives%20and%20false%20positives%20in%20generalized%20Dice%20loss\" target=\"_blank\">https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized Dice loss is the multi-class extension of,negatives and false positives in generalized Dice loss</a>.<br />\nGitHub： GitHub - JunMa11/SegLoss: A collection of loss functions for medical image segmentation <a href=\"https://github.com/JunMa11/SegLoss\" target=\"_blank\">https://github.com/JunMa11/SegLoss</a><br />\n论文：<a href=\"https://arxiv.org/pdf/2006.14822.pdf\" target=\"_blank\">https://arxiv.org/pdf/2006.14822.pdf</a></p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--损失函数与语义分割任务-br---\ndate--2021-08-07-22-29-17-br---\ntags--[深度学习--语义分割]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"6a1f818a\">title: 损失函数与语义分割任务<br />\ndate: 2021-08-07 22:29:17<br />\ntags: [深度学习, 语义分割]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.基于分布的损失函数，基于区域的损失函数，基于边界的损失函数和基于复合的损失函数（ Distribution-based,Region-based,  Boundary-based,  and  Compounded）</p><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n2.分类标签不平衡问题：<br />\n• 道路识别中，数据集拥有的正样本非常少，有时候背景负样本带来很多没必要的损失函数值的参数更新，类似噪声干扰了正样本训练，无论双分类训练还是多分类训练都存在该问题，更不用说多分类任务。<br />\n• 解决方案<br />\n损失函数本身对训练影响弱于数据集，但是，如果数据集中标签严重不平衡，还是应该选择二进制交叉熵(binary-cross entropy)之外的其他损失函数，如DiceLoss系列。<br />\n○ 普通DiceLoss损失函数<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE2.png%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE3.png%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n上面公式比较通俗，右侧部分称Dice系数（dice coefficient），由1减去就得到了DiceLoss。对于分割任务而言，绝对值X和Y分别代表ground_truth和predict_mask。一般和IoU一样作为测试的评价指数，实际训练效果非常糟糕。<br />\n○ Log-Cosh Dice Loss<br />\n普通DiceLoss由于其非凸性，它多次都无法获得最佳结果。Lovsz-softmax损失旨在通过添加使用Lovsz扩展的平滑来解决非凸损失函数的问题。同时，Log-Cosh方法已广泛用于基于回归的问题中，以平滑曲线。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE4.png%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n但是该损失函数无法在我的项目中运行（ExpLog_Dice）<br />\n○ Tversky Loss<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE5.png%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card><br />\nTversky系数是Dice系数和 Jaccard 系数的一种推广。当设置α=β=0.5，此时Tversky系数就是Dice系数。而当设置α=β=1时，此时Tversky系数就是Jaccard系数。α和β分别控制假阴性和假阳性。通过调整α和β，可以控制假阳性和假阴性之间的平衡。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE6.png%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card><br />\n○ Focal Tversky Loss<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E6%258D%259F%25E5%25A4%25B1%25E5%2587%25BD%25E6%2595%25B0%25E4%25B8%258E%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%2F%25E5%259B%25BE7.png%22%2C%22alt%22%3A%22%E5%9B%BE7%22%7D\"></card></p><p><br /></p><p>参考文章： Loss Functions for Medical Image Segmentation: A Taxonomy | by JunMa | Medium <a href=\"https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized%20Dice%20loss%20is%20the%20multi-class%20extension%20of,negatives%20and%20false%20positives%20in%20generalized%20Dice%20loss\" target=\"_blank\">https://medium.com/@junma11/loss-functions-for-medical-image-segmentation-a-taxonomy-cefa5292eec0#:~:text=Generalized Dice loss is the multi-class extension of,negatives and false positives in generalized Dice loss</a>.<br />\nGitHub： GitHub - JunMa11/SegLoss: A collection of loss functions for medical image segmentation <a href=\"https://github.com/JunMa11/SegLoss\" target=\"_blank\">https://github.com/JunMa11/SegLoss</a><br />\n论文：<a href=\"https://arxiv.org/pdf/2006.14822.pdf\" target=\"_blank\">https://arxiv.org/pdf/2006.14822.pdf</a></p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:14.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:14.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:14.000Z",
    "first_published_at": "2021-09-27T03:04:14.000Z",
    "word_count": 595,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223910,
    "slug": "grllbd",
    "title": "语义分割网络模型笔记",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"9f562739\"></a>\n## title: 语义分割网络模型笔记date: 2021-08-07 22:21:39<br />tags: [深度学习, 语义分割]<br />categories: 计算机视觉特辑\n\n• 语义分割是计算机视觉的四大任务之一（四大任务：分类a、定位b、检测b、分割c+d），在语义分割中常用的公共数据集有PASCAL VOC 2012（1.5k train 1.5k validate 20types with background）、MS COCO（83k train 41k validate 80k test 80types）<br />![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE1.jpg#alt=%E5%9B%BE1)<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE6.jpg#alt=%E5%9B%BE6)\n\n• 语义分割基本思路：<br />\n○ 基本思路：<br />\n逐个像素分类。输入整张图片进入网络，输出大小和输入一致，通道数等于类别数，分别存放各个类别在某个像元位置的概率，即可逐个像素分类。<br />\n○ 全卷积网络+反卷积网络convolution and deconvolution network：<br />\n为了使输出具有三维结构，全卷积网络中没有全连接层，只有卷积层和汇合层。但是随着卷积和汇合不断进行下去，图像的尺寸越来越小、通道数越来越多，就不能保证输出大小和输入一致，所以全卷积网络要使用反卷积和反汇合来增大空间大小。<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE2.jpg#alt=%E5%9B%BE2)<br />\n○ 反卷积（或称转置卷积） deconvolution or transpose convolution：<br />\n标准卷积的滤波器在输入的图像上滑动，每次和输入图像的局部区域点乘得到单个输出值，而反卷积的滤波器在输出图像上滑动，局部范围每个神经元值乘以滤波器对应值，得到一个输出的局部区域。标准卷积的后向过程和反卷积的前向过程完成的是同样的数学运算。而且同标准卷积滤波器一样，反卷积滤波器也是从数据中学到的。<br />\n○ 反最大汇合 max-unpooling：<br />\n通常全卷积网络是对称的结构，在最大汇合时需要记录最大值所处的局部区域范围，在对应的反最大汇合时将对应位置的输出置为输入，其余位置补零。反最大汇合可以弥补最大汇合时的空间信息丢失。反最大汇合的前向过程和最大汇合的后向过程完成的是同样的数学运算。<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE3.jpg#alt=%E5%9B%BE3)<br />\n• 语义分割常用技巧：<br />\n○ 膨胀\\空洞\\扩张卷积 dilated convolution：<br />\n这是常用于分割任务以增大感受野的一个技巧。标准卷积操作中，每个输出神经元对应的局部区域的范围内是连续的。但是，扩张卷积向标准卷积运算中引入了一个新的超参数扩张量（dilation）用于描述输入局部区域在空间位置上的间距。（当扩张量为1时，扩张卷积退化回标准卷积）扩张卷积可以在参数量不变的情况下有效提高感受野，而与经典计算机视觉手工特征相比，大的感受野是深度学习方法能取得优异性能的重要原因之一。<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE4.jpg#alt=%E5%9B%BE4)<br />\n○ 条件随机场 conditional random field(CRF)：<br />\n这是一种概率图模型，常用于微调全卷积网络的输出结果，获得更好的细节信息。它的原理是更相近的像元更可能属于相同的类别。但是这样会要考虑两两像元之间的空间关系，会极大降低运行效率。<br />\n○ 利用低层信息：<br />\n全卷积中，可以记录低层的信息，在对应的反卷积网络中的对应层采用加和（如FCN）或者沿通道方向拼接（如U-net）的方法弥补全卷积网络操作中丢失的细节和边缘信息，后者效果通常更好（如图）<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE5.jpg#alt=%E5%9B%BE5)\n\n（以上参考https://zhuanlan.zhihu.com/p/31727402）\n",
    "body_draft": "---\n\n\n<a name=\"9f562739\"></a>\n## title: 语义分割网络模型笔记date: 2021-08-07 22:21:39<br />tags: [深度学习, 语义分割]<br />categories: 计算机视觉特辑\n\n• 语义分割是计算机视觉的四大任务之一（四大任务：分类a、定位b、检测b、分割c+d），在语义分割中常用的公共数据集有PASCAL VOC 2012（1.5k train 1.5k validate 20types with background）、MS COCO（83k train 41k validate 80k test 80types）<br />![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE1.jpg#alt=%E5%9B%BE1)<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE6.jpg#alt=%E5%9B%BE6)\n\n• 语义分割基本思路：<br />\n○ 基本思路：<br />\n逐个像素分类。输入整张图片进入网络，输出大小和输入一致，通道数等于类别数，分别存放各个类别在某个像元位置的概率，即可逐个像素分类。<br />\n○ 全卷积网络+反卷积网络convolution and deconvolution network：<br />\n为了使输出具有三维结构，全卷积网络中没有全连接层，只有卷积层和汇合层。但是随着卷积和汇合不断进行下去，图像的尺寸越来越小、通道数越来越多，就不能保证输出大小和输入一致，所以全卷积网络要使用反卷积和反汇合来增大空间大小。<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE2.jpg#alt=%E5%9B%BE2)<br />\n○ 反卷积（或称转置卷积） deconvolution or transpose convolution：<br />\n标准卷积的滤波器在输入的图像上滑动，每次和输入图像的局部区域点乘得到单个输出值，而反卷积的滤波器在输出图像上滑动，局部范围每个神经元值乘以滤波器对应值，得到一个输出的局部区域。标准卷积的后向过程和反卷积的前向过程完成的是同样的数学运算。而且同标准卷积滤波器一样，反卷积滤波器也是从数据中学到的。<br />\n○ 反最大汇合 max-unpooling：<br />\n通常全卷积网络是对称的结构，在最大汇合时需要记录最大值所处的局部区域范围，在对应的反最大汇合时将对应位置的输出置为输入，其余位置补零。反最大汇合可以弥补最大汇合时的空间信息丢失。反最大汇合的前向过程和最大汇合的后向过程完成的是同样的数学运算。<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE3.jpg#alt=%E5%9B%BE3)<br />\n• 语义分割常用技巧：<br />\n○ 膨胀\\空洞\\扩张卷积 dilated convolution：<br />\n这是常用于分割任务以增大感受野的一个技巧。标准卷积操作中，每个输出神经元对应的局部区域的范围内是连续的。但是，扩张卷积向标准卷积运算中引入了一个新的超参数扩张量（dilation）用于描述输入局部区域在空间位置上的间距。（当扩张量为1时，扩张卷积退化回标准卷积）扩张卷积可以在参数量不变的情况下有效提高感受野，而与经典计算机视觉手工特征相比，大的感受野是深度学习方法能取得优异性能的重要原因之一。<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE4.jpg#alt=%E5%9B%BE4)<br />\n○ 条件随机场 conditional random field(CRF)：<br />\n这是一种概率图模型，常用于微调全卷积网络的输出结果，获得更好的细节信息。它的原理是更相近的像元更可能属于相同的类别。但是这样会要考虑两两像元之间的空间关系，会极大降低运行效率。<br />\n○ 利用低层信息：<br />\n全卷积中，可以记录低层的信息，在对应的反卷积网络中的对应层采用加和（如FCN）或者沿通道方向拼接（如U-net）的方法弥补全卷积网络操作中丢失的细节和边缘信息，后者效果通常更好（如图）<br />\n![](%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE5.jpg#alt=%E5%9B%BE5)\n\n（以上参考https://zhuanlan.zhihu.com/p/31727402）\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--语义分割网络模型笔记-br---\ndate--2021-08-07-22-21-39-br---\ntags--[深度学习--语义分割]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"9f562739\">title: 语义分割网络模型笔记<br />\ndate: 2021-08-07 22:21:39<br />\ntags: [深度学习, 语义分割]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>• 语义分割是计算机视觉的四大任务之一（四大任务：分类a、定位b、检测b、分割c+d），在语义分割中常用的公共数据集有PASCAL VOC 2012（1.5k train 1.5k validate 20types with background）、MS COCO（83k train 41k validate 80k test 80types）</p><p><img src=\"%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE1.jpg#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /><br />\n<img src=\"%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE6.jpg#alt=%E5%9B%BE6\" style=\"max-width: 600px;\" /></p><p><br /></p><p>• 语义分割基本思路：<br />\n○ 基本思路：<br />\n逐个像素分类。输入整张图片进入网络，输出大小和输入一致，通道数等于类别数，分别存放各个类别在某个像元位置的概率，即可逐个像素分类。<br />\n○ 全卷积网络+反卷积网络convolution and deconvolution network：<br />\n为了使输出具有三维结构，全卷积网络中没有全连接层，只有卷积层和汇合层。但是随着卷积和汇合不断进行下去，图像的尺寸越来越小、通道数越来越多，就不能保证输出大小和输入一致，所以全卷积网络要使用反卷积和反汇合来增大空间大小。<br />\n<img src=\"%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE2.jpg#alt=%E5%9B%BE2\" style=\"max-width: 600px;\" /><br />\n○ 反卷积（或称转置卷积） deconvolution or transpose convolution：<br />\n标准卷积的滤波器在输入的图像上滑动，每次和输入图像的局部区域点乘得到单个输出值，而反卷积的滤波器在输出图像上滑动，局部范围每个神经元值乘以滤波器对应值，得到一个输出的局部区域。标准卷积的后向过程和反卷积的前向过程完成的是同样的数学运算。而且同标准卷积滤波器一样，反卷积滤波器也是从数据中学到的。<br />\n○ 反最大汇合 max-unpooling：<br />\n通常全卷积网络是对称的结构，在最大汇合时需要记录最大值所处的局部区域范围，在对应的反最大汇合时将对应位置的输出置为输入，其余位置补零。反最大汇合可以弥补最大汇合时的空间信息丢失。反最大汇合的前向过程和最大汇合的后向过程完成的是同样的数学运算。<br />\n<img src=\"%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE3.jpg#alt=%E5%9B%BE3\" style=\"max-width: 600px;\" /><br />\n• 语义分割常用技巧：<br />\n○ 膨胀\\空洞\\扩张卷积 dilated convolution：<br />\n这是常用于分割任务以增大感受野的一个技巧。标准卷积操作中，每个输出神经元对应的局部区域的范围内是连续的。但是，扩张卷积向标准卷积运算中引入了一个新的超参数扩张量（dilation）用于描述输入局部区域在空间位置上的间距。（当扩张量为1时，扩张卷积退化回标准卷积）扩张卷积可以在参数量不变的情况下有效提高感受野，而与经典计算机视觉手工特征相比，大的感受野是深度学习方法能取得优异性能的重要原因之一。<br />\n<img src=\"%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE4.jpg#alt=%E5%9B%BE4\" style=\"max-width: 600px;\" /><br />\n○ 条件随机场 conditional random field(CRF)：<br />\n这是一种概率图模型，常用于微调全卷积网络的输出结果，获得更好的细节信息。它的原理是更相近的像元更可能属于相同的类别。但是这样会要考虑两两像元之间的空间关系，会极大降低运行效率。<br />\n○ 利用低层信息：<br />\n全卷积中，可以记录低层的信息，在对应的反卷积网络中的对应层采用加和（如FCN）或者沿通道方向拼接（如U-net）的方法弥补全卷积网络操作中丢失的细节和边缘信息，后者效果通常更好（如图）<br />\n<img src=\"%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%9B%BE5.jpg#alt=%E5%9B%BE5\" style=\"max-width: 600px;\" /></p><p><br /></p><p>（以上参考https://zhuanlan.zhihu.com/p/31727402）</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--语义分割网络模型笔记-br---\ndate--2021-08-07-22-21-39-br---\ntags--[深度学习--语义分割]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"9f562739\">title: 语义分割网络模型笔记<br />\ndate: 2021-08-07 22:21:39<br />\ntags: [深度学习, 语义分割]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>• 语义分割是计算机视觉的四大任务之一（四大任务：分类a、定位b、检测b、分割c+d），在语义分割中常用的公共数据集有PASCAL VOC 2012（1.5k train 1.5k validate 20types with background）、MS COCO（83k train 41k validate 80k test 80types）</p><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE1.jpg%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE6.jpg%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card></p><p><br /></p><p>• 语义分割基本思路：<br />\n○ 基本思路：<br />\n逐个像素分类。输入整张图片进入网络，输出大小和输入一致，通道数等于类别数，分别存放各个类别在某个像元位置的概率，即可逐个像素分类。<br />\n○ 全卷积网络+反卷积网络convolution and deconvolution network：<br />\n为了使输出具有三维结构，全卷积网络中没有全连接层，只有卷积层和汇合层。但是随着卷积和汇合不断进行下去，图像的尺寸越来越小、通道数越来越多，就不能保证输出大小和输入一致，所以全卷积网络要使用反卷积和反汇合来增大空间大小。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE2.jpg%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n○ 反卷积（或称转置卷积） deconvolution or transpose convolution：<br />\n标准卷积的滤波器在输入的图像上滑动，每次和输入图像的局部区域点乘得到单个输出值，而反卷积的滤波器在输出图像上滑动，局部范围每个神经元值乘以滤波器对应值，得到一个输出的局部区域。标准卷积的后向过程和反卷积的前向过程完成的是同样的数学运算。而且同标准卷积滤波器一样，反卷积滤波器也是从数据中学到的。<br />\n○ 反最大汇合 max-unpooling：<br />\n通常全卷积网络是对称的结构，在最大汇合时需要记录最大值所处的局部区域范围，在对应的反最大汇合时将对应位置的输出置为输入，其余位置补零。反最大汇合可以弥补最大汇合时的空间信息丢失。反最大汇合的前向过程和最大汇合的后向过程完成的是同样的数学运算。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE3.jpg%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n• 语义分割常用技巧：<br />\n○ 膨胀\\空洞\\扩张卷积 dilated convolution：<br />\n这是常用于分割任务以增大感受野的一个技巧。标准卷积操作中，每个输出神经元对应的局部区域的范围内是连续的。但是，扩张卷积向标准卷积运算中引入了一个新的超参数扩张量（dilation）用于描述输入局部区域在空间位置上的间距。（当扩张量为1时，扩张卷积退化回标准卷积）扩张卷积可以在参数量不变的情况下有效提高感受野，而与经典计算机视觉手工特征相比，大的感受野是深度学习方法能取得优异性能的重要原因之一。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE4.jpg%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n○ 条件随机场 conditional random field(CRF)：<br />\n这是一种概率图模型，常用于微调全卷积网络的输出结果，获得更好的细节信息。它的原理是更相近的像元更可能属于相同的类别。但是这样会要考虑两两像元之间的空间关系，会极大降低运行效率。<br />\n○ 利用低层信息：<br />\n全卷积中，可以记录低层的信息，在对应的反卷积网络中的对应层采用加和（如FCN）或者沿通道方向拼接（如U-net）的方法弥补全卷积网络操作中丢失的细节和边缘信息，后者效果通常更好（如图）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE5.jpg%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card></p><p><br /></p><p>（以上参考https://zhuanlan.zhihu.com/p/31727402）</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--语义分割网络模型笔记-br---\ndate--2021-08-07-22-21-39-br---\ntags--[深度学习--语义分割]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"9f562739\">title: 语义分割网络模型笔记<br />\ndate: 2021-08-07 22:21:39<br />\ntags: [深度学习, 语义分割]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>• 语义分割是计算机视觉的四大任务之一（四大任务：分类a、定位b、检测b、分割c+d），在语义分割中常用的公共数据集有PASCAL VOC 2012（1.5k train 1.5k validate 20types with background）、MS COCO（83k train 41k validate 80k test 80types）</p><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE1.jpg%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card><br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE6.jpg%22%2C%22alt%22%3A%22%E5%9B%BE6%22%7D\"></card></p><p><br /></p><p>• 语义分割基本思路：<br />\n○ 基本思路：<br />\n逐个像素分类。输入整张图片进入网络，输出大小和输入一致，通道数等于类别数，分别存放各个类别在某个像元位置的概率，即可逐个像素分类。<br />\n○ 全卷积网络+反卷积网络convolution and deconvolution network：<br />\n为了使输出具有三维结构，全卷积网络中没有全连接层，只有卷积层和汇合层。但是随着卷积和汇合不断进行下去，图像的尺寸越来越小、通道数越来越多，就不能保证输出大小和输入一致，所以全卷积网络要使用反卷积和反汇合来增大空间大小。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE2.jpg%22%2C%22alt%22%3A%22%E5%9B%BE2%22%7D\"></card><br />\n○ 反卷积（或称转置卷积） deconvolution or transpose convolution：<br />\n标准卷积的滤波器在输入的图像上滑动，每次和输入图像的局部区域点乘得到单个输出值，而反卷积的滤波器在输出图像上滑动，局部范围每个神经元值乘以滤波器对应值，得到一个输出的局部区域。标准卷积的后向过程和反卷积的前向过程完成的是同样的数学运算。而且同标准卷积滤波器一样，反卷积滤波器也是从数据中学到的。<br />\n○ 反最大汇合 max-unpooling：<br />\n通常全卷积网络是对称的结构，在最大汇合时需要记录最大值所处的局部区域范围，在对应的反最大汇合时将对应位置的输出置为输入，其余位置补零。反最大汇合可以弥补最大汇合时的空间信息丢失。反最大汇合的前向过程和最大汇合的后向过程完成的是同样的数学运算。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE3.jpg%22%2C%22alt%22%3A%22%E5%9B%BE3%22%7D\"></card><br />\n• 语义分割常用技巧：<br />\n○ 膨胀\\空洞\\扩张卷积 dilated convolution：<br />\n这是常用于分割任务以增大感受野的一个技巧。标准卷积操作中，每个输出神经元对应的局部区域的范围内是连续的。但是，扩张卷积向标准卷积运算中引入了一个新的超参数扩张量（dilation）用于描述输入局部区域在空间位置上的间距。（当扩张量为1时，扩张卷积退化回标准卷积）扩张卷积可以在参数量不变的情况下有效提高感受野，而与经典计算机视觉手工特征相比，大的感受野是深度学习方法能取得优异性能的重要原因之一。<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE4.jpg%22%2C%22alt%22%3A%22%E5%9B%BE4%22%7D\"></card><br />\n○ 条件随机场 conditional random field(CRF)：<br />\n这是一种概率图模型，常用于微调全卷积网络的输出结果，获得更好的细节信息。它的原理是更相近的像元更可能属于相同的类别。但是这样会要考虑两两像元之间的空间关系，会极大降低运行效率。<br />\n○ 利用低层信息：<br />\n全卷积中，可以记录低层的信息，在对应的反卷积网络中的对应层采用加和（如FCN）或者沿通道方向拼接（如U-net）的方法弥补全卷积网络操作中丢失的细节和边缘信息，后者效果通常更好（如图）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E8%25AF%25AD%25E4%25B9%2589%25E5%2588%2586%25E5%2589%25B2%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E7%25AC%2594%25E8%25AE%25B0%2F%25E5%259B%25BE5.jpg%22%2C%22alt%22%3A%22%E5%9B%BE5%22%7D\"></card></p><p><br /></p><p>（以上参考https://zhuanlan.zhihu.com/p/31727402）</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:09.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:09.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:09.000Z",
    "first_published_at": "2021-09-27T03:04:09.000Z",
    "word_count": 1028,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223898,
    "slug": "xnqb2e",
    "title": "美食之美",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"4c2f74be\"></a>\n## title: 美食之美——《雅舍谈吃》date: 2021-07-06 23:07:04<br />tags: 美食<br />categories: 生活随笔<br />swiper_index: 8<br />swiper_desc: 简单好用的 hexo 博客文章置顶插件！<br />swiper_cover: /img/weixin.png\n\n```\n美，不尽收；食，不尽全。 ——题记\n```\n\n  谈到美食，正如饥肠辘辘的人，心里面急迫等待着吃的味觉。但不是所谓，仅仅为着生存。追寻美食的目标，不像一种世俗的冲动，正如雅舍先生题序「我以为要求美味固是人欲，然而何曾有背于天理？如果天理不包括美味的要求在内，上天之人，在舌头上为什么要生那么多的味蕾」。<br />  吃得好，是让人幸福，是对舌尖感受的升华，一旦提到耳熟能详的菜名，人的愉悦便像剑拔弩张，舌尖一触，百般馋舌。左右结构的「馋」字，右边两点比喻两腿迅猛，迅猛狡兔之肉，并非丰足，但人为了啖其美味，愿意逐此狡兔，故写作馋。西施舌、火腿、醋溜鱼、烤羊肉、烧鸭……谁若吃一口，也不至于在脑袋里臆想，两腿一跺，手掌一直，啪的一下，就算有事缠身也无暇顾及。然而，追求高级的味觉，就必然失去点东西，尤其时间宝贵，未必能每次都放纵自己。<br />\n  今年除夕，我从繁忙学业中抽身，冒着病毒的风险，踉跄到广东家中度过佳节。目的尚且鲜明，写在文章也就印证我所说为了吃美食。老母亲的美味已经不是天天所得，不回一趟家，不吃慈母饭。而明年除夕，已经计划好的美食清单，都在湖南临武，是为了外婆欢庆大寿，为了庆幸生能继续享用湘菜美味。诚然，计划是幸福的计划，我学业若是耽误，便影响我母亲回乡的心情。<br />\n  学业之中，不代表就缺乏美味。学校前门小吃街，第一条正中间的店面以「炒」为技艺，炒粉丝、炒饭、炒土豆粉、炒米线……每份炒制不少料、不过熟，香味浓郁滑入咽喉。旁边五碗小菜随取，勺筷俱全，好不心爽幸福。校外也有全州拌饭，馋嘴烤鱼、淮南牛肉汤、鸡蛋灌饼、特制酸奶等等玲琅满，如饕餮大餐，本人如数家珍，乐子甚广。<br />\n  但不是美食就令人幸福的，美食反被美食误，吃得不好，有可能还要怪罪一下美食。<br />\n  美食为了尝而点，而不是为了点而尝。打开一个外卖软件，铺天盖地的优惠券、广告条、满减促销，全然改变了美食服务的本质。美食不是为了优惠而美，但你看，我想起26元的双层牛肉芝士汉堡，打开外卖软件，又开始送我优惠券，一张是满27减5，一张是满80减9。我心念的汉堡计划被搁置一旁。现在，我购物车换了又换，想法改了又改，点了一家鸡架，满减很高，大份鸡架配油饼、薯条、龙串、千叶只要81，满减后43，优惠券折至34，天啊，真捡大便宜了，一个人，母亲常骂我浪费，也怕生冷不好吃，终于胃饱难入。于是，半个月后的一天，我说：「我心心念念的大汉堡还没吃到呢」，于是又习惯地，打开了外卖软件……<br />\n  啖美味的人是得爽口，而不是失口德。点到为止，也是嘴的道规。母亲常嘱咐我「什么东西都不能吃多」，但你看，考试结束，我路过一家烤番薯，摊主一旁慢悠悠削菠萝，菠萝酸甜爽口，头脑一昏，要来四根。老板连忙感谢，我心生奇怪。一路上我大快朵颐，直到第三根已然不对劲，牙齿酸疼，满口酥麻。是啊，我知道我吃多了，但是当时人已然傻了，没办法，又已然泛起恶心。<br />\n  美食之美，若天仙之佳，似陋室之雅。雅舍谈吃，谈世俗之赏，谈高雅之堂。南京翠香阁的早茶、北京全聚德的烧鸭，绝不同于广东潮州的街边烂摊子，不带有地域的歧视，不带有阶层的歧视，雅舍或许能尽情在破烂中寻味潮州，若是「破烂」登上大雅之堂的高级餐席，也不感觉一丝违和。但是，真世上能为高价路边摊买单的人已然不多见，多人不敢斗胆，为了金钱的缺憾。别人跟我谈到吃，我更愿意关注在吃本身上，谈钱，色变。但美食不是阶级之物。凡人也能有凡人的美味，大雅之堂也未必不入凡人；大雅食材未必得凡人认可，没有凡人认可也不称美食。<br />\n  美，有庐山仙境，有墙头杏花，观不可尽收；食，有满汉全席，有菜汤小食，尝不可尽全。却有人生百态，五味杂陈。文章，有百科全书，有一本便笺，若不是看不完，怎么会藏书如山，孜孜不倦。吃饭，若不是吃不完，怎么会馋如饕餮，感想良多。我写的字，就是把味蕾的感想说出来。可，不是我的味蕾，是我熙熙攘攘间，听闻的许多味蕾……\n",
    "body_draft": "---\n\n\n<a name=\"4c2f74be\"></a>\n## title: 美食之美——《雅舍谈吃》date: 2021-07-06 23:07:04<br />tags: 美食<br />categories: 生活随笔<br />swiper_index: 8<br />swiper_desc: 简单好用的 hexo 博客文章置顶插件！<br />swiper_cover: /img/weixin.png\n\n```\n美，不尽收；食，不尽全。 ——题记\n```\n\n  谈到美食，正如饥肠辘辘的人，心里面急迫等待着吃的味觉。但不是所谓，仅仅为着生存。追寻美食的目标，不像一种世俗的冲动，正如雅舍先生题序「我以为要求美味固是人欲，然而何曾有背于天理？如果天理不包括美味的要求在内，上天之人，在舌头上为什么要生那么多的味蕾」。<br />  吃得好，是让人幸福，是对舌尖感受的升华，一旦提到耳熟能详的菜名，人的愉悦便像剑拔弩张，舌尖一触，百般馋舌。左右结构的「馋」字，右边两点比喻两腿迅猛，迅猛狡兔之肉，并非丰足，但人为了啖其美味，愿意逐此狡兔，故写作馋。西施舌、火腿、醋溜鱼、烤羊肉、烧鸭……谁若吃一口，也不至于在脑袋里臆想，两腿一跺，手掌一直，啪的一下，就算有事缠身也无暇顾及。然而，追求高级的味觉，就必然失去点东西，尤其时间宝贵，未必能每次都放纵自己。<br />\n  今年除夕，我从繁忙学业中抽身，冒着病毒的风险，踉跄到广东家中度过佳节。目的尚且鲜明，写在文章也就印证我所说为了吃美食。老母亲的美味已经不是天天所得，不回一趟家，不吃慈母饭。而明年除夕，已经计划好的美食清单，都在湖南临武，是为了外婆欢庆大寿，为了庆幸生能继续享用湘菜美味。诚然，计划是幸福的计划，我学业若是耽误，便影响我母亲回乡的心情。<br />\n  学业之中，不代表就缺乏美味。学校前门小吃街，第一条正中间的店面以「炒」为技艺，炒粉丝、炒饭、炒土豆粉、炒米线……每份炒制不少料、不过熟，香味浓郁滑入咽喉。旁边五碗小菜随取，勺筷俱全，好不心爽幸福。校外也有全州拌饭，馋嘴烤鱼、淮南牛肉汤、鸡蛋灌饼、特制酸奶等等玲琅满，如饕餮大餐，本人如数家珍，乐子甚广。<br />\n  但不是美食就令人幸福的，美食反被美食误，吃得不好，有可能还要怪罪一下美食。<br />\n  美食为了尝而点，而不是为了点而尝。打开一个外卖软件，铺天盖地的优惠券、广告条、满减促销，全然改变了美食服务的本质。美食不是为了优惠而美，但你看，我想起26元的双层牛肉芝士汉堡，打开外卖软件，又开始送我优惠券，一张是满27减5，一张是满80减9。我心念的汉堡计划被搁置一旁。现在，我购物车换了又换，想法改了又改，点了一家鸡架，满减很高，大份鸡架配油饼、薯条、龙串、千叶只要81，满减后43，优惠券折至34，天啊，真捡大便宜了，一个人，母亲常骂我浪费，也怕生冷不好吃，终于胃饱难入。于是，半个月后的一天，我说：「我心心念念的大汉堡还没吃到呢」，于是又习惯地，打开了外卖软件……<br />\n  啖美味的人是得爽口，而不是失口德。点到为止，也是嘴的道规。母亲常嘱咐我「什么东西都不能吃多」，但你看，考试结束，我路过一家烤番薯，摊主一旁慢悠悠削菠萝，菠萝酸甜爽口，头脑一昏，要来四根。老板连忙感谢，我心生奇怪。一路上我大快朵颐，直到第三根已然不对劲，牙齿酸疼，满口酥麻。是啊，我知道我吃多了，但是当时人已然傻了，没办法，又已然泛起恶心。<br />\n  美食之美，若天仙之佳，似陋室之雅。雅舍谈吃，谈世俗之赏，谈高雅之堂。南京翠香阁的早茶、北京全聚德的烧鸭，绝不同于广东潮州的街边烂摊子，不带有地域的歧视，不带有阶层的歧视，雅舍或许能尽情在破烂中寻味潮州，若是「破烂」登上大雅之堂的高级餐席，也不感觉一丝违和。但是，真世上能为高价路边摊买单的人已然不多见，多人不敢斗胆，为了金钱的缺憾。别人跟我谈到吃，我更愿意关注在吃本身上，谈钱，色变。但美食不是阶级之物。凡人也能有凡人的美味，大雅之堂也未必不入凡人；大雅食材未必得凡人认可，没有凡人认可也不称美食。<br />\n  美，有庐山仙境，有墙头杏花，观不可尽收；食，有满汉全席，有菜汤小食，尝不可尽全。却有人生百态，五味杂陈。文章，有百科全书，有一本便笺，若不是看不完，怎么会藏书如山，孜孜不倦。吃饭，若不是吃不完，怎么会馋如饕餮，感想良多。我写的字，就是把味蕾的感想说出来。可，不是我的味蕾，是我熙熙攘攘间，听闻的许多味蕾……\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--美食之美——《雅舍谈吃》-br---\ndate--2021-07-06-23-07-04-br---\ntags--美食-br---\ncategories--生活随笔-br---\nswiper_index--8-br---\nswiper_desc--简单好用的-hexo-博客文章置顶插件！-br---\nswiper_cover---img-weixin.png\"></a><h2 id=\"4c2f74be\">title: 美食之美——《雅舍谈吃》<br />\ndate: 2021-07-06 23:07:04<br />\ntags: 美食<br />\ncategories: 生活随笔<br />\nswiper_index: 8<br />\nswiper_desc: 简单好用的 hexo 博客文章置顶插件！<br />\nswiper_cover: /img/weixin.png</h2><p><br /></p><pre><code>美，不尽收；食，不尽全。 ——题记</code></pre><p><br /></p><p>  谈到美食，正如饥肠辘辘的人，心里面急迫等待着吃的味觉。但不是所谓，仅仅为着生存。追寻美食的目标，不像一种世俗的冲动，正如雅舍先生题序「我以为要求美味固是人欲，然而何曾有背于天理？如果天理不包括美味的要求在内，上天之人，在舌头上为什么要生那么多的味蕾」。</p><p>  吃得好，是让人幸福，是对舌尖感受的升华，一旦提到耳熟能详的菜名，人的愉悦便像剑拔弩张，舌尖一触，百般馋舌。左右结构的「馋」字，右边两点比喻两腿迅猛，迅猛狡兔之肉，并非丰足，但人为了啖其美味，愿意逐此狡兔，故写作馋。西施舌、火腿、醋溜鱼、烤羊肉、烧鸭……谁若吃一口，也不至于在脑袋里臆想，两腿一跺，手掌一直，啪的一下，就算有事缠身也无暇顾及。然而，追求高级的味觉，就必然失去点东西，尤其时间宝贵，未必能每次都放纵自己。<br />\n  今年除夕，我从繁忙学业中抽身，冒着病毒的风险，踉跄到广东家中度过佳节。目的尚且鲜明，写在文章也就印证我所说为了吃美食。老母亲的美味已经不是天天所得，不回一趟家，不吃慈母饭。而明年除夕，已经计划好的美食清单，都在湖南临武，是为了外婆欢庆大寿，为了庆幸生能继续享用湘菜美味。诚然，计划是幸福的计划，我学业若是耽误，便影响我母亲回乡的心情。<br />\n  学业之中，不代表就缺乏美味。学校前门小吃街，第一条正中间的店面以「炒」为技艺，炒粉丝、炒饭、炒土豆粉、炒米线……每份炒制不少料、不过熟，香味浓郁滑入咽喉。旁边五碗小菜随取，勺筷俱全，好不心爽幸福。校外也有全州拌饭，馋嘴烤鱼、淮南牛肉汤、鸡蛋灌饼、特制酸奶等等玲琅满，如饕餮大餐，本人如数家珍，乐子甚广。<br />\n  但不是美食就令人幸福的，美食反被美食误，吃得不好，有可能还要怪罪一下美食。<br />\n  美食为了尝而点，而不是为了点而尝。打开一个外卖软件，铺天盖地的优惠券、广告条、满减促销，全然改变了美食服务的本质。美食不是为了优惠而美，但你看，我想起26元的双层牛肉芝士汉堡，打开外卖软件，又开始送我优惠券，一张是满27减5，一张是满80减9。我心念的汉堡计划被搁置一旁。现在，我购物车换了又换，想法改了又改，点了一家鸡架，满减很高，大份鸡架配油饼、薯条、龙串、千叶只要81，满减后43，优惠券折至34，天啊，真捡大便宜了，一个人，母亲常骂我浪费，也怕生冷不好吃，终于胃饱难入。于是，半个月后的一天，我说：「我心心念念的大汉堡还没吃到呢」，于是又习惯地，打开了外卖软件……<br />\n  啖美味的人是得爽口，而不是失口德。点到为止，也是嘴的道规。母亲常嘱咐我「什么东西都不能吃多」，但你看，考试结束，我路过一家烤番薯，摊主一旁慢悠悠削菠萝，菠萝酸甜爽口，头脑一昏，要来四根。老板连忙感谢，我心生奇怪。一路上我大快朵颐，直到第三根已然不对劲，牙齿酸疼，满口酥麻。是啊，我知道我吃多了，但是当时人已然傻了，没办法，又已然泛起恶心。<br />\n  美食之美，若天仙之佳，似陋室之雅。雅舍谈吃，谈世俗之赏，谈高雅之堂。南京翠香阁的早茶、北京全聚德的烧鸭，绝不同于广东潮州的街边烂摊子，不带有地域的歧视，不带有阶层的歧视，雅舍或许能尽情在破烂中寻味潮州，若是「破烂」登上大雅之堂的高级餐席，也不感觉一丝违和。但是，真世上能为高价路边摊买单的人已然不多见，多人不敢斗胆，为了金钱的缺憾。别人跟我谈到吃，我更愿意关注在吃本身上，谈钱，色变。但美食不是阶级之物。凡人也能有凡人的美味，大雅之堂也未必不入凡人；大雅食材未必得凡人认可，没有凡人认可也不称美食。<br />\n  美，有庐山仙境，有墙头杏花，观不可尽收；食，有满汉全席，有菜汤小食，尝不可尽全。却有人生百态，五味杂陈。文章，有百科全书，有一本便笺，若不是看不完，怎么会藏书如山，孜孜不倦。吃饭，若不是吃不完，怎么会馋如饕餮，感想良多。我写的字，就是把味蕾的感想说出来。可，不是我的味蕾，是我熙熙攘攘间，听闻的许多味蕾……</p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--美食之美——《雅舍谈吃》-br---\ndate--2021-07-06-23-07-04-br---\ntags--美食-br---\ncategories--生活随笔-br---\nswiper_index--8-br---\nswiper_desc--简单好用的-hexo-博客文章置顶插件！-br---\nswiper_cover---img-weixin.png\"></a><h2 id=\"4c2f74be\">title: 美食之美——《雅舍谈吃》<br />\ndate: 2021-07-06 23:07:04<br />\ntags: 美食<br />\ncategories: 生活随笔<br />\nswiper_index: 8<br />\nswiper_desc: 简单好用的 hexo 博客文章置顶插件！<br />\nswiper_cover: /img/weixin.png</h2><p><br /></p><card type=\"block\" name=\"codeblock\" value=\"data:%7B%22id%22%3A%221ba6f44b%22%2C%22code%22%3A%22%E7%BE%8E%EF%BC%8C%E4%B8%8D%E5%B0%BD%E6%94%B6%EF%BC%9B%E9%A3%9F%EF%BC%8C%E4%B8%8D%E5%B0%BD%E5%85%A8%E3%80%82%20%E2%80%94%E2%80%94%E9%A2%98%E8%AE%B0%22%7D\"></card><p><br /></p><p>  谈到美食，正如饥肠辘辘的人，心里面急迫等待着吃的味觉。但不是所谓，仅仅为着生存。追寻美食的目标，不像一种世俗的冲动，正如雅舍先生题序「我以为要求美味固是人欲，然而何曾有背于天理？如果天理不包括美味的要求在内，上天之人，在舌头上为什么要生那么多的味蕾」。</p><p>  吃得好，是让人幸福，是对舌尖感受的升华，一旦提到耳熟能详的菜名，人的愉悦便像剑拔弩张，舌尖一触，百般馋舌。左右结构的「馋」字，右边两点比喻两腿迅猛，迅猛狡兔之肉，并非丰足，但人为了啖其美味，愿意逐此狡兔，故写作馋。西施舌、火腿、醋溜鱼、烤羊肉、烧鸭……谁若吃一口，也不至于在脑袋里臆想，两腿一跺，手掌一直，啪的一下，就算有事缠身也无暇顾及。然而，追求高级的味觉，就必然失去点东西，尤其时间宝贵，未必能每次都放纵自己。<br />\n  今年除夕，我从繁忙学业中抽身，冒着病毒的风险，踉跄到广东家中度过佳节。目的尚且鲜明，写在文章也就印证我所说为了吃美食。老母亲的美味已经不是天天所得，不回一趟家，不吃慈母饭。而明年除夕，已经计划好的美食清单，都在湖南临武，是为了外婆欢庆大寿，为了庆幸生能继续享用湘菜美味。诚然，计划是幸福的计划，我学业若是耽误，便影响我母亲回乡的心情。<br />\n  学业之中，不代表就缺乏美味。学校前门小吃街，第一条正中间的店面以「炒」为技艺，炒粉丝、炒饭、炒土豆粉、炒米线……每份炒制不少料、不过熟，香味浓郁滑入咽喉。旁边五碗小菜随取，勺筷俱全，好不心爽幸福。校外也有全州拌饭，馋嘴烤鱼、淮南牛肉汤、鸡蛋灌饼、特制酸奶等等玲琅满，如饕餮大餐，本人如数家珍，乐子甚广。<br />\n  但不是美食就令人幸福的，美食反被美食误，吃得不好，有可能还要怪罪一下美食。<br />\n  美食为了尝而点，而不是为了点而尝。打开一个外卖软件，铺天盖地的优惠券、广告条、满减促销，全然改变了美食服务的本质。美食不是为了优惠而美，但你看，我想起26元的双层牛肉芝士汉堡，打开外卖软件，又开始送我优惠券，一张是满27减5，一张是满80减9。我心念的汉堡计划被搁置一旁。现在，我购物车换了又换，想法改了又改，点了一家鸡架，满减很高，大份鸡架配油饼、薯条、龙串、千叶只要81，满减后43，优惠券折至34，天啊，真捡大便宜了，一个人，母亲常骂我浪费，也怕生冷不好吃，终于胃饱难入。于是，半个月后的一天，我说：「我心心念念的大汉堡还没吃到呢」，于是又习惯地，打开了外卖软件……<br />\n  啖美味的人是得爽口，而不是失口德。点到为止，也是嘴的道规。母亲常嘱咐我「什么东西都不能吃多」，但你看，考试结束，我路过一家烤番薯，摊主一旁慢悠悠削菠萝，菠萝酸甜爽口，头脑一昏，要来四根。老板连忙感谢，我心生奇怪。一路上我大快朵颐，直到第三根已然不对劲，牙齿酸疼，满口酥麻。是啊，我知道我吃多了，但是当时人已然傻了，没办法，又已然泛起恶心。<br />\n  美食之美，若天仙之佳，似陋室之雅。雅舍谈吃，谈世俗之赏，谈高雅之堂。南京翠香阁的早茶、北京全聚德的烧鸭，绝不同于广东潮州的街边烂摊子，不带有地域的歧视，不带有阶层的歧视，雅舍或许能尽情在破烂中寻味潮州，若是「破烂」登上大雅之堂的高级餐席，也不感觉一丝违和。但是，真世上能为高价路边摊买单的人已然不多见，多人不敢斗胆，为了金钱的缺憾。别人跟我谈到吃，我更愿意关注在吃本身上，谈钱，色变。但美食不是阶级之物。凡人也能有凡人的美味，大雅之堂也未必不入凡人；大雅食材未必得凡人认可，没有凡人认可也不称美食。<br />\n  美，有庐山仙境，有墙头杏花，观不可尽收；食，有满汉全席，有菜汤小食，尝不可尽全。却有人生百态，五味杂陈。文章，有百科全书，有一本便笺，若不是看不完，怎么会藏书如山，孜孜不倦。吃饭，若不是吃不完，怎么会馋如饕餮，感想良多。我写的字，就是把味蕾的感想说出来。可，不是我的味蕾，是我熙熙攘攘间，听闻的许多味蕾……</p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--美食之美——《雅舍谈吃》-br---\ndate--2021-07-06-23-07-04-br---\ntags--美食-br---\ncategories--生活随笔-br---\nswiper_index--8-br---\nswiper_desc--简单好用的-hexo-博客文章置顶插件！-br---\nswiper_cover---img-weixin.png\"></a><h2 id=\"4c2f74be\">title: 美食之美——《雅舍谈吃》<br />\ndate: 2021-07-06 23:07:04<br />\ntags: 美食<br />\ncategories: 生活随笔<br />\nswiper_index: 8<br />\nswiper_desc: 简单好用的 hexo 博客文章置顶插件！<br />\nswiper_cover: /img/weixin.png</h2><p><br /></p><card type=\"block\" name=\"codeblock\" value=\"data:%7B%22id%22%3A%221ba6f44b%22%2C%22code%22%3A%22%E7%BE%8E%EF%BC%8C%E4%B8%8D%E5%B0%BD%E6%94%B6%EF%BC%9B%E9%A3%9F%EF%BC%8C%E4%B8%8D%E5%B0%BD%E5%85%A8%E3%80%82%20%E2%80%94%E2%80%94%E9%A2%98%E8%AE%B0%22%7D\"></card><p><br /></p><p>  谈到美食，正如饥肠辘辘的人，心里面急迫等待着吃的味觉。但不是所谓，仅仅为着生存。追寻美食的目标，不像一种世俗的冲动，正如雅舍先生题序「我以为要求美味固是人欲，然而何曾有背于天理？如果天理不包括美味的要求在内，上天之人，在舌头上为什么要生那么多的味蕾」。</p><p>  吃得好，是让人幸福，是对舌尖感受的升华，一旦提到耳熟能详的菜名，人的愉悦便像剑拔弩张，舌尖一触，百般馋舌。左右结构的「馋」字，右边两点比喻两腿迅猛，迅猛狡兔之肉，并非丰足，但人为了啖其美味，愿意逐此狡兔，故写作馋。西施舌、火腿、醋溜鱼、烤羊肉、烧鸭……谁若吃一口，也不至于在脑袋里臆想，两腿一跺，手掌一直，啪的一下，就算有事缠身也无暇顾及。然而，追求高级的味觉，就必然失去点东西，尤其时间宝贵，未必能每次都放纵自己。<br />\n  今年除夕，我从繁忙学业中抽身，冒着病毒的风险，踉跄到广东家中度过佳节。目的尚且鲜明，写在文章也就印证我所说为了吃美食。老母亲的美味已经不是天天所得，不回一趟家，不吃慈母饭。而明年除夕，已经计划好的美食清单，都在湖南临武，是为了外婆欢庆大寿，为了庆幸生能继续享用湘菜美味。诚然，计划是幸福的计划，我学业若是耽误，便影响我母亲回乡的心情。<br />\n  学业之中，不代表就缺乏美味。学校前门小吃街，第一条正中间的店面以「炒」为技艺，炒粉丝、炒饭、炒土豆粉、炒米线……每份炒制不少料、不过熟，香味浓郁滑入咽喉。旁边五碗小菜随取，勺筷俱全，好不心爽幸福。校外也有全州拌饭，馋嘴烤鱼、淮南牛肉汤、鸡蛋灌饼、特制酸奶等等玲琅满，如饕餮大餐，本人如数家珍，乐子甚广。<br />\n  但不是美食就令人幸福的，美食反被美食误，吃得不好，有可能还要怪罪一下美食。<br />\n  美食为了尝而点，而不是为了点而尝。打开一个外卖软件，铺天盖地的优惠券、广告条、满减促销，全然改变了美食服务的本质。美食不是为了优惠而美，但你看，我想起26元的双层牛肉芝士汉堡，打开外卖软件，又开始送我优惠券，一张是满27减5，一张是满80减9。我心念的汉堡计划被搁置一旁。现在，我购物车换了又换，想法改了又改，点了一家鸡架，满减很高，大份鸡架配油饼、薯条、龙串、千叶只要81，满减后43，优惠券折至34，天啊，真捡大便宜了，一个人，母亲常骂我浪费，也怕生冷不好吃，终于胃饱难入。于是，半个月后的一天，我说：「我心心念念的大汉堡还没吃到呢」，于是又习惯地，打开了外卖软件……<br />\n  啖美味的人是得爽口，而不是失口德。点到为止，也是嘴的道规。母亲常嘱咐我「什么东西都不能吃多」，但你看，考试结束，我路过一家烤番薯，摊主一旁慢悠悠削菠萝，菠萝酸甜爽口，头脑一昏，要来四根。老板连忙感谢，我心生奇怪。一路上我大快朵颐，直到第三根已然不对劲，牙齿酸疼，满口酥麻。是啊，我知道我吃多了，但是当时人已然傻了，没办法，又已然泛起恶心。<br />\n  美食之美，若天仙之佳，似陋室之雅。雅舍谈吃，谈世俗之赏，谈高雅之堂。南京翠香阁的早茶、北京全聚德的烧鸭，绝不同于广东潮州的街边烂摊子，不带有地域的歧视，不带有阶层的歧视，雅舍或许能尽情在破烂中寻味潮州，若是「破烂」登上大雅之堂的高级餐席，也不感觉一丝违和。但是，真世上能为高价路边摊买单的人已然不多见，多人不敢斗胆，为了金钱的缺憾。别人跟我谈到吃，我更愿意关注在吃本身上，谈钱，色变。但美食不是阶级之物。凡人也能有凡人的美味，大雅之堂也未必不入凡人；大雅食材未必得凡人认可，没有凡人认可也不称美食。<br />\n  美，有庐山仙境，有墙头杏花，观不可尽收；食，有满汉全席，有菜汤小食，尝不可尽全。却有人生百态，五味杂陈。文章，有百科全书，有一本便笺，若不是看不完，怎么会藏书如山，孜孜不倦。吃饭，若不是吃不完，怎么会馋如饕餮，感想良多。我写的字，就是把味蕾的感想说出来。可，不是我的味蕾，是我熙熙攘攘间，听闻的许多味蕾……</p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:05.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:05.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:05.000Z",
    "first_published_at": "2021-09-27T03:04:05.000Z",
    "word_count": 1600,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 54223889,
    "slug": "tvbg16",
    "title": "分割任务下数据集增广",
    "book_id": 20965598,
    "book": {
      "id": 20965598,
      "type": "Book",
      "slug": "kepggi",
      "name": "博客",
      "user_id": 22806711,
      "description": "",
      "creator_id": 22806711,
      "public": 0,
      "items_count": 13,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2021-09-27T03:05:00.630Z",
      "updated_at": "2021-09-27T03:05:05.000Z",
      "created_at": "2021-09-27T02:59:10.000Z",
      "namespace": "buluwasitiantianwen/kepggi",
      "user": {
        "id": 22806711,
        "type": "User",
        "login": "buluwasitiantianwen",
        "name": "布鲁瓦丝甜甜文",
        "description": null,
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
        "books_count": 2,
        "public_books_count": 0,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2021-09-27T02:57:48.000Z",
        "updated_at": "2021-09-27T03:05:00.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 22806711,
    "creator": {
      "id": 22806711,
      "type": "User",
      "login": "buluwasitiantianwen",
      "name": "布鲁瓦丝甜甜文",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "books_count": 2,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2021-09-27T02:57:48.000Z",
      "updated_at": "2021-09-27T03:05:00.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "---\n\n\n<a name=\"f58478a7\"></a>\n## title: 分割任务下数据集增广date: 2021-08-07 22:39:14<br />tags: [深度学习, 语义分割, 数据]<br />categories: 计算机视觉特辑\n\n1.常用增广算法<br />\n• 图像变换：<br />\n○ 颜色增强<br />\n○ 亮度增强<br />\n○ 颜色随机<br />• 数量增广：<br />\n○ 角度旋转<br />\n• 重要图像变换：<br />\n○ 随机缩放<br />\n○ 椒盐化\n\n2.有序增广<br />\n有各式各样的数据增广方式，但是有的增广给训练带来的效果更为显著，这样各种增广方式就不能简单各执行一次就好，而要按照一定次序逐一嵌套地执行，目前增广方式可分为三类重要等级（左至右重要性递增）：图像变换>>数量增广>>重要图像变换。<br />\n• 第一步，对当前数据集完成各简单图像变换，如颜色增强、亮度增强、颜色随机。这一步进行了对泛化优化效果较差的增广，因为是第一次增广产生的数据量增长最少。<br />\n• 第二部，对第一步增广的数据集执行角度旋转，这一步大量增加了数据量。<br />\n• 最后，执行重要图像变换，如随机缩放、椒盐化，这是对泛化优化提供重要贡献的增广方法，这样对前面大量的增广数据完成全覆盖式重要图像变换。（值得强调的是，尺度上的变化对于感受野的优化是最大的，这也造就了随即缩放效益最优的地位，当然同时也会进一步数量增广）<br />\n![](%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1%E4%B8%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A2%9E%E5%B9%BF/%E5%9B%BE1.png#alt=%E5%9B%BE1)\n",
    "body_draft": "---\n\n\n<a name=\"f58478a7\"></a>\n## title: 分割任务下数据集增广date: 2021-08-07 22:39:14<br />tags: [深度学习, 语义分割, 数据]<br />categories: 计算机视觉特辑\n\n1.常用增广算法<br />\n• 图像变换：<br />\n○ 颜色增强<br />\n○ 亮度增强<br />\n○ 颜色随机<br />• 数量增广：<br />\n○ 角度旋转<br />\n• 重要图像变换：<br />\n○ 随机缩放<br />\n○ 椒盐化\n\n2.有序增广<br />\n有各式各样的数据增广方式，但是有的增广给训练带来的效果更为显著，这样各种增广方式就不能简单各执行一次就好，而要按照一定次序逐一嵌套地执行，目前增广方式可分为三类重要等级（左至右重要性递增）：图像变换>>数量增广>>重要图像变换。<br />\n• 第一步，对当前数据集完成各简单图像变换，如颜色增强、亮度增强、颜色随机。这一步进行了对泛化优化效果较差的增广，因为是第一次增广产生的数据量增长最少。<br />\n• 第二部，对第一步增广的数据集执行角度旋转，这一步大量增加了数据量。<br />\n• 最后，执行重要图像变换，如随机缩放、椒盐化，这是对泛化优化提供重要贡献的增广方法，这样对前面大量的增广数据完成全覆盖式重要图像变换。（值得强调的是，尺度上的变化对于感受野的优化是最大的，这也造就了随即缩放效益最优的地位，当然同时也会进一步数量增广）<br />\n![](%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1%E4%B8%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A2%9E%E5%B9%BF/%E5%9B%BE1.png#alt=%E5%9B%BE1)\n",
    "body_html": "<!doctype html><hr /><p><br /></p><a name=\"title--分割任务下数据集增广-br---\ndate--2021-08-07-22-39-14-br---\ntags--[深度学习--语义分割--数据]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"f58478a7\">title: 分割任务下数据集增广<br />\ndate: 2021-08-07 22:39:14<br />\ntags: [深度学习, 语义分割, 数据]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.常用增广算法<br />\n• 图像变换：<br />\n○ 颜色增强<br />\n○ 亮度增强<br />\n○ 颜色随机</p><p>• 数量增广：<br />\n○ 角度旋转<br />\n• 重要图像变换：<br />\n○ 随机缩放<br />\n○ 椒盐化</p><p><br /></p><p>2.有序增广<br />\n有各式各样的数据增广方式，但是有的增广给训练带来的效果更为显著，这样各种增广方式就不能简单各执行一次就好，而要按照一定次序逐一嵌套地执行，目前增广方式可分为三类重要等级（左至右重要性递增）：图像变换&gt;&gt;数量增广&gt;&gt;重要图像变换。<br />\n• 第一步，对当前数据集完成各简单图像变换，如颜色增强、亮度增强、颜色随机。这一步进行了对泛化优化效果较差的增广，因为是第一次增广产生的数据量增长最少。<br />\n• 第二部，对第一步增广的数据集执行角度旋转，这一步大量增加了数据量。<br />\n• 最后，执行重要图像变换，如随机缩放、椒盐化，这是对泛化优化提供重要贡献的增广方法，这样对前面大量的增广数据完成全覆盖式重要图像变换。（值得强调的是，尺度上的变化对于感受野的优化是最大的，这也造就了随即缩放效益最优的地位，当然同时也会进一步数量增广）<br />\n<img src=\"%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1%E4%B8%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A2%9E%E5%B9%BF/%E5%9B%BE1.png#alt=%E5%9B%BE1\" style=\"max-width: 600px;\" /></p>",
    "body_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--分割任务下数据集增广-br---\ndate--2021-08-07-22-39-14-br---\ntags--[深度学习--语义分割--数据]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"f58478a7\">title: 分割任务下数据集增广<br />\ndate: 2021-08-07 22:39:14<br />\ntags: [深度学习, 语义分割, 数据]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.常用增广算法<br />\n• 图像变换：<br />\n○ 颜色增强<br />\n○ 亮度增强<br />\n○ 颜色随机</p><p>• 数量增广：<br />\n○ 角度旋转<br />\n• 重要图像变换：<br />\n○ 随机缩放<br />\n○ 椒盐化</p><p><br /></p><p>2.有序增广<br />\n有各式各样的数据增广方式，但是有的增广给训练带来的效果更为显著，这样各种增广方式就不能简单各执行一次就好，而要按照一定次序逐一嵌套地执行，目前增广方式可分为三类重要等级（左至右重要性递增）：图像变换&gt;&gt;数量增广&gt;&gt;重要图像变换。<br />\n• 第一步，对当前数据集完成各简单图像变换，如颜色增强、亮度增强、颜色随机。这一步进行了对泛化优化效果较差的增广，因为是第一次增广产生的数据量增长最少。<br />\n• 第二部，对第一步增广的数据集执行角度旋转，这一步大量增加了数据量。<br />\n• 最后，执行重要图像变换，如随机缩放、椒盐化，这是对泛化优化提供重要贡献的增广方法，这样对前面大量的增广数据完成全覆盖式重要图像变换。（值得强调的是，尺度上的变化对于感受野的优化是最大的，这也造就了随即缩放效益最优的地位，当然同时也会进一步数量增广）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%25E4%25B8%258B%25E6%2595%25B0%25E6%258D%25AE%25E9%259B%2586%25E5%25A2%259E%25E5%25B9%25BF%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card></p>",
    "body_draft_lake": "<!doctype lake><card type=\"block\" name=\"hr\"></card><p><br /></p><a name=\"title--分割任务下数据集增广-br---\ndate--2021-08-07-22-39-14-br---\ntags--[深度学习--语义分割--数据]-br---\ncategories--计算机视觉特辑\"></a><h2 id=\"f58478a7\">title: 分割任务下数据集增广<br />\ndate: 2021-08-07 22:39:14<br />\ntags: [深度学习, 语义分割, 数据]<br />\ncategories: 计算机视觉特辑</h2><p><br /></p><p>1.常用增广算法<br />\n• 图像变换：<br />\n○ 颜色增强<br />\n○ 亮度增强<br />\n○ 颜色随机</p><p>• 数量增广：<br />\n○ 角度旋转<br />\n• 重要图像变换：<br />\n○ 随机缩放<br />\n○ 椒盐化</p><p><br /></p><p>2.有序增广<br />\n有各式各样的数据增广方式，但是有的增广给训练带来的效果更为显著，这样各种增广方式就不能简单各执行一次就好，而要按照一定次序逐一嵌套地执行，目前增广方式可分为三类重要等级（左至右重要性递增）：图像变换&gt;&gt;数量增广&gt;&gt;重要图像变换。<br />\n• 第一步，对当前数据集完成各简单图像变换，如颜色增强、亮度增强、颜色随机。这一步进行了对泛化优化效果较差的增广，因为是第一次增广产生的数据量增长最少。<br />\n• 第二部，对第一步增广的数据集执行角度旋转，这一步大量增加了数据量。<br />\n• 最后，执行重要图像变换，如随机缩放、椒盐化，这是对泛化优化提供重要贡献的增广方法，这样对前面大量的增广数据完成全覆盖式重要图像变换。（值得强调的是，尺度上的变化对于感受野的优化是最大的，这也造就了随即缩放效益最优的地位，当然同时也会进一步数量增广）<br />\n<card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22%25E5%2588%2586%25E5%2589%25B2%25E4%25BB%25BB%25E5%258A%25A1%25E4%25B8%258B%25E6%2595%25B0%25E6%258D%25AE%25E9%259B%2586%25E5%25A2%259E%25E5%25B9%25BF%2F%25E5%259B%25BE1.png%22%2C%22alt%22%3A%22%E5%9B%BE1%22%7D\"></card></p>",
    "public": 1,
    "status": 1,
    "view_status": 0,
    "read_status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2021-09-27T03:04:00.000Z",
    "deleted_at": null,
    "created_at": "2021-09-27T03:04:00.000Z",
    "updated_at": "2021-09-27T07:04:09.000Z",
    "published_at": "2021-09-27T03:04:00.000Z",
    "first_published_at": "2021-09-27T03:04:00.000Z",
    "word_count": 444,
    "cover": null,
    "description": null,
    "custom_description": null,
    "hits": 0,
    "_serializer": "v2.doc_detail"
  }
]